{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0df3fba6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                   // Or use any other 2.x version here\n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                // Not required since almond 0.7.0 (will be automatically added when importing spark)\n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.DataFrame\n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.SparkSession\n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.storage.StorageLevel\n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                    \u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.5` // Or use any other 2.x version here\n",
    "import $ivy.`sh.almond::almond-spark:0.10.9` // Not required since almond 0.7.0 (will be automatically added when importing spark)\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.storage.StorageLevel\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "import org.apache.spark.sql._\n",
    "import $ivy.`org.apache.spark::spark-mllib:2.4.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aa2ed54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\n",
       "\u001b[39m\r\n",
       "\u001b[36mrootLogger\u001b[39m: \u001b[32mLogger\u001b[39m = org.apache.log4j.spi.RootLogger@683e7062"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.log4j.{Level, Logger}\n",
    "\n",
    "val rootLogger = Logger.getRootLogger()\n",
    "rootLogger.setLevel(Level.ERROR)\n",
    "\n",
    "Logger.getLogger(\"org.apache.spark\").setLevel(Level.WARN)\n",
    "Logger.getLogger(\"org.spark-project\").setLevel(Level.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0d9e9f6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "23/03/25 02:31:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/03/25 02:31:14 ERROR Shell: Failed to locate the winutils binary in the hadoop binary path\n",
      "java.io.IOException: Could not locate executable null\\bin\\winutils.exe in the Hadoop binaries.\n",
      "\tat org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)\n",
      "\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)\n",
      "\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)\n",
      "\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)\n",
      "\tat org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)\n",
      "\tat org.apache.hadoop.security.Groups.<init>(Groups.java:93)\n",
      "\tat org.apache.hadoop.security.Groups.<init>(Groups.java:73)\n",
      "\tat org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)\n",
      "\tat org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2422)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2422)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:293)\n",
      "\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2520)\n",
      "\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$5(SparkSession.scala:935)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)\n",
      "\tat ammonite.$sess.cmd2$Helper.<init>(cmd2.sc:7)\n",
      "\tat ammonite.$sess.cmd2$.<init>(cmd2.sc:7)\n",
      "\tat ammonite.$sess.cmd2$.<clinit>(cmd2.sc)\n",
      "\tat ammonite.$sess.cmd2.$main(cmd2.sc)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat ammonite.runtime.Evaluator$$anon$1.$anonfun$evalMain$1(Evaluator.scala:108)\n",
      "\tat ammonite.util.Util$.withContextClassloader(Util.scala:24)\n",
      "\tat ammonite.runtime.Evaluator$$anon$1.evalMain(Evaluator.scala:90)\n",
      "\tat ammonite.runtime.Evaluator$$anon$1.$anonfun$processLine$2(Evaluator.scala:127)\n",
      "\tat ammonite.util.Catching.map(Res.scala:117)\n",
      "\tat ammonite.runtime.Evaluator$$anon$1.$anonfun$processLine$1(Evaluator.scala:121)\n",
      "\tat ammonite.util.Res$Success.flatMap(Res.scala:62)\n",
      "\tat ammonite.runtime.Evaluator$$anon$1.processLine(Evaluator.scala:120)\n",
      "\tat ammonite.interp.Interpreter.$anonfun$evaluateLine$4(Interpreter.scala:295)\n",
      "\tat ammonite.util.Res$Success.flatMap(Res.scala:62)\n",
      "\tat ammonite.interp.Interpreter.$anonfun$evaluateLine$2(Interpreter.scala:281)\n",
      "\tat ammonite.util.Catching.flatMap(Res.scala:115)\n",
      "\tat ammonite.interp.Interpreter.evaluateLine(Interpreter.scala:280)\n",
      "\tat ammonite.interp.Interpreter.$anonfun$processLine$6(Interpreter.scala:268)\n",
      "\tat ammonite.util.Res$Success.flatMap(Res.scala:62)\n",
      "\tat ammonite.interp.Interpreter.$anonfun$processLine$4(Interpreter.scala:251)\n",
      "\tat ammonite.util.Res$Success.flatMap(Res.scala:62)\n",
      "\tat ammonite.interp.Interpreter.$anonfun$processLine$2(Interpreter.scala:244)\n",
      "\tat ammonite.util.Catching.flatMap(Res.scala:115)\n",
      "\tat ammonite.interp.Interpreter.processLine(Interpreter.scala:243)\n",
      "\tat almond.Execute.$anonfun$ammResult$11(Execute.scala:238)\n",
      "\tat almond.internals.CaptureImpl.$anonfun$apply$2(CaptureImpl.scala:53)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat scala.Console$.withErr(Console.scala:196)\n",
      "\tat almond.internals.CaptureImpl.$anonfun$apply$1(CaptureImpl.scala:45)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat scala.Console$.withOut(Console.scala:167)\n",
      "\tat almond.internals.CaptureImpl.apply(CaptureImpl.scala:45)\n",
      "\tat almond.Execute.capturingOutput(Execute.scala:166)\n",
      "\tat almond.Execute.$anonfun$ammResult$10(Execute.scala:225)\n",
      "\tat almond.Execute.$anonfun$withClientStdin$1(Execute.scala:146)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat scala.Console$.withIn(Console.scala:230)\n",
      "\tat almond.Execute.withClientStdin(Execute.scala:142)\n",
      "\tat almond.Execute.$anonfun$ammResult$9(Execute.scala:225)\n",
      "\tat almond.Execute.withInputManager(Execute.scala:134)\n",
      "\tat almond.Execute.$anonfun$ammResult$8(Execute.scala:224)\n",
      "\tat ammonite.repl.Signaller.apply(Signaller.scala:28)\n",
      "\tat almond.Execute.interruptible(Execute.scala:183)\n",
      "\tat almond.Execute.$anonfun$ammResult$7(Execute.scala:223)\n",
      "\tat ammonite.util.Res$Success.flatMap(Res.scala:62)\n",
      "\tat almond.Execute.$anonfun$ammResult$1(Execute.scala:214)\n",
      "\tat almond.Execute.withOutputHandler(Execute.scala:157)\n",
      "\tat almond.Execute.ammResult(Execute.scala:214)\n",
      "\tat almond.Execute.apply(Execute.scala:311)\n",
      "\tat almond.ScalaInterpreter.execute(ScalaInterpreter.scala:127)\n",
      "\tat almond.interpreter.InterpreterToIOInterpreter.$anonfun$execute$2(InterpreterToIOInterpreter.scala:69)\n",
      "\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:87)\n",
      "\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:366)\n",
      "\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:387)\n",
      "\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:330)\n",
      "\tat cats.effect.internals.IOShift$Tick.run(IOShift.scala:36)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "23/03/25 02:31:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\n",
       "\u001b[39m\r\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@17239ad"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "\n",
    "val spark = {\n",
    "    SparkSession.builder()\n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"Detection_Fraude_Master2\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", 6)\n",
    "    .getOrCreate()\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392cd1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcb_fraude\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Time: decimal(10,0), V1: double ... 29 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cb_fraude = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .load(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f28bc681",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Time: decimal(10,0) (nullable = true)\n",
      " |-- V1: double (nullable = true)\n",
      " |-- V2: double (nullable = true)\n",
      " |-- V3: double (nullable = true)\n",
      " |-- V4: double (nullable = true)\n",
      " |-- V5: double (nullable = true)\n",
      " |-- V6: double (nullable = true)\n",
      " |-- V7: double (nullable = true)\n",
      " |-- V8: double (nullable = true)\n",
      " |-- V9: double (nullable = true)\n",
      " |-- V10: double (nullable = true)\n",
      " |-- V11: double (nullable = true)\n",
      " |-- V12: double (nullable = true)\n",
      " |-- V13: double (nullable = true)\n",
      " |-- V14: double (nullable = true)\n",
      " |-- V15: double (nullable = true)\n",
      " |-- V16: double (nullable = true)\n",
      " |-- V17: double (nullable = true)\n",
      " |-- V18: double (nullable = true)\n",
      " |-- V19: double (nullable = true)\n",
      " |-- V20: double (nullable = true)\n",
      " |-- V21: double (nullable = true)\n",
      " |-- V22: double (nullable = true)\n",
      " |-- V23: double (nullable = true)\n",
      " |-- V24: double (nullable = true)\n",
      " |-- V25: double (nullable = true)\n",
      " |-- V26: double (nullable = true)\n",
      " |-- V27: double (nullable = true)\n",
      " |-- V28: double (nullable = true)\n",
      " |-- Amount: double (nullable = true)\n",
      " |-- Class: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Afficher le schéma du DataFrame\n",
    "cb_fraude.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c360fe",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 02:31:24 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+\n",
      "|summary|             Time|                  V1|                  V2|                  V3|                  V4|                  V5|                  V6|                  V7|                  V8|                  V9|                 V10|                 V11|                 V12|                 V13|                 V14|                 V15|                 V16|                 V17|                 V18|                 V19|                 V20|                 V21|                 V22|                 V23|                 V24|                 V25|                 V26|                 V27|                 V28|            Amount|               Class|\n",
      "+-------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+\n",
      "|  count|           284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|            284807|              284807|\n",
      "|   mean|       94813.8596|8.222932923226221...|7.983430022549729...|-1.34121624378835...|1.663746816699363...|8.749839304714502...|1.633409782613674...|-5.92370507673189...|1.219468935944471...|-2.53778583338298...|2.095650380919303...|1.922409949429974...|-8.54227012412820...|1.230845323726604...|8.933458195233146...|5.162085852580654...|1.455578878861379...|-2.69041591759925...|1.084948140064508...|1.036249216926954...|5.692185606077957...|1.433774135612290...|-5.14132893452202...|2.786217077869855...|4.499660746459591...|5.987572516912296...|1.621933601956259...|-3.82356401642491...|-1.25339851354030...| 88.34961925093077|0.001727485630620034|\n",
      "| stddev|47488.14595456596|  1.9586958038574867|  1.6513085794769964|  1.5162550051777708|  1.4158685749409208|    1.38024673403144|  1.3322710897575762|   1.237093598182666|  1.1943529026692041|  1.0986320892243215|  1.0888497654025178|  1.0207130277115575|  0.9992013895301428|  0.9952742301251546|  0.9585956112570647|  0.9153160116104383|  0.8762528873883694|   0.849337063674389|  0.8381762095288423|  0.8140405007685776|  0.7709250248871167|  0.7345240143713132|   0.725701560440911|    0.62446029559499|  0.6056470678271606|  0.5212780705409427|  0.4822270132610572| 0.40363249496503073|  0.3300832641602509|250.12010924018867|0.041527189635465006|\n",
      "|    min|                0|    -56.407509631329|   -72.7157275629303|   -48.3255893623954|   -5.68317119816995|   -113.743306711146|   -26.1605059358433|   -43.5572415712451|   -73.2167184552674|   -13.4340663182301|   -24.5882624372475|   -4.79747346479757|   -18.6837146333443|   -5.79188120632084|   -19.2143254902614|   -4.49894467676621|   -14.1298545174931|   -25.1627993693248|   -9.49874592104677|   -7.21352743017759|    -54.497720494566|   -34.8303821448146|    -10.933143697655|   -44.8077352037913|   -2.83662691870341|   -10.2953970749851|   -2.60455055280817|   -22.5656793207827|   -15.4300839055349|               0.0|                   0|\n",
      "|    max|           172792|    2.45492999121121|    22.0577289904909|    9.38255843282114|    16.8753440335975|    34.8016658766686|    73.3016255459646|    120.589493945238|    20.0072083651213|    15.5949946071278|    23.7451361206545|    12.0189131816199|     7.8483920756446|    7.12688295859376|    10.5267660517847|    8.87774159774277|    17.3151115176278|    9.25352625047285|    5.04106918541184|    5.59197142733558|    39.4209042482199|    27.2028391573154|    10.5030900899454|    22.5284116897749|    4.58454913689817|    7.51958867870916|     3.5173456116238|    31.6121981061363|    33.8478078188831|          25691.16|                   1|\n",
      "+-------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Afficher les statistiques sommaires\n",
    "cb_fraude.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d74e265f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud ratio: 0.001727485630620034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mfraudCount\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m492L\u001b[39m\r\n",
       "\u001b[36mtotalCount\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m284807L\u001b[39m\r\n",
       "\u001b[36mfraudRatio\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.001727485630620034\u001b[39m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Calculer la proportion de transactions frauduleuses\n",
    "val fraudCount = cb_fraude.filter(col(\"Class\") === 1).count()\n",
    "val totalCount = cb_fraude.count()\n",
    "val fraudRatio = fraudCount.toDouble / totalCount.toDouble\n",
    "println(s\"Fraud ratio: $fraudRatio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47bceb01",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.types._\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Visualiser la distribution des valeurs pour la colonne Amount\n",
    "import spark.implicits._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "651a5867",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            Amount|\n",
      "+-------+------------------+\n",
      "|  count|            284807|\n",
      "|   mean| 88.34961925093077|\n",
      "| stddev|250.12010924018867|\n",
      "|    min|               0.0|\n",
      "|    max|          25691.16|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres8_1\u001b[39m: (\u001b[32mArray\u001b[39m[\u001b[32mDouble\u001b[39m], \u001b[32mArray\u001b[39m[\u001b[32mLong\u001b[39m]) = (\n",
       "  \u001b[33mArray\u001b[39m(\n",
       "    \u001b[32m0.0\u001b[39m,\n",
       "    \u001b[32m2569.116\u001b[39m,\n",
       "    \u001b[32m5138.232\u001b[39m,\n",
       "    \u001b[32m7707.348\u001b[39m,\n",
       "    \u001b[32m10276.464\u001b[39m,\n",
       "    \u001b[32m12845.58\u001b[39m,\n",
       "    \u001b[32m15414.696\u001b[39m,\n",
       "    \u001b[32m17983.811999999998\u001b[39m,\n",
       "    \u001b[32m20552.928\u001b[39m,\n",
       "    \u001b[32m23122.044\u001b[39m,\n",
       "    \u001b[32m25691.16\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mArray\u001b[39m(\u001b[32m284395L\u001b[39m, \u001b[32m360L\u001b[39m, \u001b[32m36L\u001b[39m, \u001b[32m10L\u001b[39m, \u001b[32m2L\u001b[39m, \u001b[32m1L\u001b[39m, \u001b[32m0L\u001b[39m, \u001b[32m2L\u001b[39m, \u001b[32m0L\u001b[39m, \u001b[32m1L\u001b[39m)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_fraude.select(\"Amount\").describe().show()\n",
    "cb_fraude.select(\"Amount\").rdd.map(r => r(0).asInstanceOf[Double]).histogram(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c46c6409",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|             Time|\n",
      "+-------+-----------------+\n",
      "|  count|           284807|\n",
      "|   mean|       94813.8596|\n",
      "| stddev|47488.14595456596|\n",
      "|    min|                0|\n",
      "|    max|           172792|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 02:31:27 ERROR Executor: Exception in task 11.0 in stage 14.0 (TID 113)\n",
      "java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double\n",
      "\tat scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1(cmd9.sc:2)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1$adapted(cmd9.sc:2)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.reversed(TraversableOnce.scala:122)\n",
      "\tat scala.collection.TraversableOnce.reversed$(TraversableOnce.scala:117)\n",
      "\tat scala.collection.AbstractIterator.reversed(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.foldRight(TraversableOnce.scala:194)\n",
      "\tat scala.collection.TraversableOnce.foldRight$(TraversableOnce.scala:193)\n",
      "\tat scala.collection.AbstractIterator.foldRight(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$histogram$3(DoubleRDDFunctions.scala:133)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "23/03/25 02:31:27 ERROR Executor: Exception in task 1.0 in stage 14.0 (TID 103)\n",
      "java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double\n",
      "\tat scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1(cmd9.sc:2)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1$adapted(cmd9.sc:2)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.reversed(TraversableOnce.scala:122)\n",
      "\tat scala.collection.TraversableOnce.reversed$(TraversableOnce.scala:117)\n",
      "\tat scala.collection.AbstractIterator.reversed(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.foldRight(TraversableOnce.scala:194)\n",
      "\tat scala.collection.TraversableOnce.foldRight$(TraversableOnce.scala:193)\n",
      "\tat scala.collection.AbstractIterator.foldRight(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$histogram$3(DoubleRDDFunctions.scala:133)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "23/03/25 02:31:27 ERROR Executor: Exception in task 0.0 in stage 14.0 (TID 102)\n",
      "java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double\n",
      "\tat scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1(cmd9.sc:2)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1$adapted(cmd9.sc:2)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.reversed(TraversableOnce.scala:122)\n",
      "\tat scala.collection.TraversableOnce.reversed$(TraversableOnce.scala:117)\n",
      "\tat scala.collection.AbstractIterator.reversed(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.foldRight(TraversableOnce.scala:194)\n",
      "\tat scala.collection.TraversableOnce.foldRight$(TraversableOnce.scala:193)\n",
      "\tat scala.collection.AbstractIterator.foldRight(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$histogram$3(DoubleRDDFunctions.scala:133)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "23/03/25 02:31:27 ERROR Executor: Exception in task 4.0 in stage 14.0 (TID 106)\n",
      "java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double\n",
      "\tat scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1(cmd9.sc:2)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1$adapted(cmd9.sc:2)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.reversed(TraversableOnce.scala:122)\n",
      "\tat scala.collection.TraversableOnce.reversed$(TraversableOnce.scala:117)\n",
      "\tat scala.collection.AbstractIterator.reversed(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.foldRight(TraversableOnce.scala:194)\n",
      "\tat scala.collection.TraversableOnce.foldRight$(TraversableOnce.scala:193)\n",
      "\tat scala.collection.AbstractIterator.foldRight(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$histogram$3(DoubleRDDFunctions.scala:133)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 02:31:27 ERROR Executor: Exception in task 2.0 in stage 14.0 (TID 104)\n",
      "java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double\n",
      "\tat scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1(cmd9.sc:2)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1$adapted(cmd9.sc:2)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.reversed(TraversableOnce.scala:122)\n",
      "\tat scala.collection.TraversableOnce.reversed$(TraversableOnce.scala:117)\n",
      "\tat scala.collection.AbstractIterator.reversed(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.foldRight(TraversableOnce.scala:194)\n",
      "\tat scala.collection.TraversableOnce.foldRight$(TraversableOnce.scala:193)\n",
      "\tat scala.collection.AbstractIterator.foldRight(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$histogram$3(DoubleRDDFunctions.scala:133)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "23/03/25 02:31:27 ERROR Executor: Exception in task 8.0 in stage 14.0 (TID 110)\n",
      "java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double\n",
      "\tat scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1(cmd9.sc:2)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1$adapted(cmd9.sc:2)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.reversed(TraversableOnce.scala:122)\n",
      "\tat scala.collection.TraversableOnce.reversed$(TraversableOnce.scala:117)\n",
      "\tat scala.collection.AbstractIterator.reversed(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.foldRight(TraversableOnce.scala:194)\n",
      "\tat scala.collection.TraversableOnce.foldRight$(TraversableOnce.scala:193)\n",
      "\tat scala.collection.AbstractIterator.foldRight(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$histogram$3(DoubleRDDFunctions.scala:133)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "23/03/25 02:31:27 ERROR Executor: Exception in task 3.0 in stage 14.0 (TID 105)\n",
      "java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double\n",
      "\tat scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1(cmd9.sc:2)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1$adapted(cmd9.sc:2)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.reversed(TraversableOnce.scala:122)\n",
      "\tat scala.collection.TraversableOnce.reversed$(TraversableOnce.scala:117)\n",
      "\tat scala.collection.AbstractIterator.reversed(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.foldRight(TraversableOnce.scala:194)\n",
      "\tat scala.collection.TraversableOnce.foldRight$(TraversableOnce.scala:193)\n",
      "\tat scala.collection.AbstractIterator.foldRight(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$histogram$3(DoubleRDDFunctions.scala:133)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "23/03/25 02:31:27 ERROR Executor: Exception in task 6.0 in stage 14.0 (TID 108)\n",
      "java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double\n",
      "\tat scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1(cmd9.sc:2)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1$adapted(cmd9.sc:2)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.reversed(TraversableOnce.scala:122)\n",
      "\tat scala.collection.TraversableOnce.reversed$(TraversableOnce.scala:117)\n",
      "\tat scala.collection.AbstractIterator.reversed(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.foldRight(TraversableOnce.scala:194)\n",
      "\tat scala.collection.TraversableOnce.foldRight$(TraversableOnce.scala:193)\n",
      "\tat scala.collection.AbstractIterator.foldRight(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$histogram$3(DoubleRDDFunctions.scala:133)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "23/03/25 02:31:27 ERROR Executor: Exception in task 9.0 in stage 14.0 (TID 111)\n",
      "java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double\n",
      "\tat scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1(cmd9.sc:2)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1$adapted(cmd9.sc:2)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.reversed(TraversableOnce.scala:122)\n",
      "\tat scala.collection.TraversableOnce.reversed$(TraversableOnce.scala:117)\n",
      "\tat scala.collection.AbstractIterator.reversed(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.foldRight(TraversableOnce.scala:194)\n",
      "\tat scala.collection.TraversableOnce.foldRight$(TraversableOnce.scala:193)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tat scala.collection.AbstractIterator.foldRight(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$histogram$3(DoubleRDDFunctions.scala:133)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "23/03/25 02:31:27 ERROR Executor: Exception in task 5.0 in stage 14.0 (TID 107)\n",
      "java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double\n",
      "\tat scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1(cmd9.sc:2)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1$adapted(cmd9.sc:2)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.reversed(TraversableOnce.scala:122)\n",
      "\tat scala.collection.TraversableOnce.reversed$(TraversableOnce.scala:117)\n",
      "\tat scala.collection.AbstractIterator.reversed(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.foldRight(TraversableOnce.scala:194)\n",
      "\tat scala.collection.TraversableOnce.foldRight$(TraversableOnce.scala:193)\n",
      "\tat scala.collection.AbstractIterator.foldRight(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$histogram$3(DoubleRDDFunctions.scala:133)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "23/03/25 02:31:27 ERROR Executor: Exception in task 7.0 in stage 14.0 (TID 109)\n",
      "java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double\n",
      "\tat scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1(cmd9.sc:2)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1$adapted(cmd9.sc:2)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.reversed(TraversableOnce.scala:122)\n",
      "\tat scala.collection.TraversableOnce.reversed$(TraversableOnce.scala:117)\n",
      "\tat scala.collection.AbstractIterator.reversed(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.foldRight(TraversableOnce.scala:194)\n",
      "\tat scala.collection.TraversableOnce.foldRight$(TraversableOnce.scala:193)\n",
      "\tat scala.collection.AbstractIterator.foldRight(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$histogram$3(DoubleRDDFunctions.scala:133)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "23/03/25 02:31:27 ERROR Executor: Exception in task 10.0 in stage 14.0 (TID 112)\n",
      "java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double\n",
      "\tat scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1(cmd9.sc:2)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1$adapted(cmd9.sc:2)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.reversed(TraversableOnce.scala:122)\n",
      "\tat scala.collection.TraversableOnce.reversed$(TraversableOnce.scala:117)\n",
      "\tat scala.collection.AbstractIterator.reversed(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.foldRight(TraversableOnce.scala:194)\n",
      "\tat scala.collection.TraversableOnce.foldRight$(TraversableOnce.scala:193)\n",
      "\tat scala.collection.AbstractIterator.foldRight(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$histogram$3(DoubleRDDFunctions.scala:133)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "23/03/25 02:31:27 WARN TaskSetManager: Lost task 5.0 in stage 14.0 (TID 107, localhost, executor driver): java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double\n",
      "\tat scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1(cmd9.sc:2)\n",
      "\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1$adapted(cmd9.sc:2)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.reversed(TraversableOnce.scala:122)\n",
      "\tat scala.collection.TraversableOnce.reversed$(TraversableOnce.scala:117)\n",
      "\tat scala.collection.AbstractIterator.reversed(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.foldRight(TraversableOnce.scala:194)\n",
      "\tat scala.collection.TraversableOnce.foldRight$(TraversableOnce.scala:193)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tat scala.collection.AbstractIterator.foldRight(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$histogram$3(DoubleRDDFunctions.scala:133)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "23/03/25 02:31:27 ERROR TaskSetManager: Task 5 in stage 14.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31morg.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 14.0 failed 1 times, most recent failure: Lost task 5.0 in stage 14.0 (TID 107, localhost, executor driver): java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double\r\n\tat scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)\r\n\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1(cmd9.sc:2)\r\n\tat ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1$adapted(cmd9.sc:2)\r\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\r\n\tat scala.collection.TraversableOnce.reversed(TraversableOnce.scala:122)\r\n\tat scala.collection.TraversableOnce.reversed$(TraversableOnce.scala:117)\r\n\tat scala.collection.AbstractIterator.reversed(Iterator.scala:1431)\r\n\tat scala.collection.TraversableOnce.foldRight(TraversableOnce.scala:194)\r\n\tat scala.collection.TraversableOnce.foldRight$(TraversableOnce.scala:193)\r\n\tat scala.collection.AbstractIterator.foldRight(Iterator.scala:1431)\r\n\tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$histogram$3(DoubleRDDFunctions.scala:133)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:823)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:823)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\u001b[39m\r\n  org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m1891\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m1879\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m1878\u001b[39m)\r\n  scala.collection.mutable.ResizableArray.foreach(\u001b[32mResizableArray.scala\u001b[39m:\u001b[32m62\u001b[39m)\r\n  scala.collection.mutable.ResizableArray.foreach$(\u001b[32mResizableArray.scala\u001b[39m:\u001b[32m55\u001b[39m)\r\n  scala.collection.mutable.ArrayBuffer.foreach(\u001b[32mArrayBuffer.scala\u001b[39m:\u001b[32m49\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.abortStage(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m1878\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m927\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m927\u001b[39m)\r\n  scala.Option.foreach(\u001b[32mOption.scala\u001b[39m:\u001b[32m407\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m927\u001b[39m)\r\n  org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m2112\u001b[39m)\r\n  org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m2061\u001b[39m)\r\n  org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m2050\u001b[39m)\r\n  org.apache.spark.util.EventLoop$$anon$1.run(\u001b[32mEventLoop.scala\u001b[39m:\u001b[32m49\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.runJob(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m738\u001b[39m)\r\n  org.apache.spark.SparkContext.runJob(\u001b[32mSparkContext.scala\u001b[39m:\u001b[32m2061\u001b[39m)\r\n  org.apache.spark.SparkContext.runJob(\u001b[32mSparkContext.scala\u001b[39m:\u001b[32m2158\u001b[39m)\r\n  org.apache.spark.rdd.RDD.$anonfun$reduce$1(\u001b[32mRDD.scala\u001b[39m:\u001b[32m1080\u001b[39m)\r\n  org.apache.spark.rdd.RDDOperationScope$.withScope(\u001b[32mRDDOperationScope.scala\u001b[39m:\u001b[32m151\u001b[39m)\r\n  org.apache.spark.rdd.RDDOperationScope$.withScope(\u001b[32mRDDOperationScope.scala\u001b[39m:\u001b[32m112\u001b[39m)\r\n  org.apache.spark.rdd.RDD.withScope(\u001b[32mRDD.scala\u001b[39m:\u001b[32m385\u001b[39m)\r\n  org.apache.spark.rdd.RDD.reduce(\u001b[32mRDD.scala\u001b[39m:\u001b[32m1062\u001b[39m)\r\n  org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$histogram$1(\u001b[32mDoubleRDDFunctions.scala\u001b[39m:\u001b[32m134\u001b[39m)\r\n  org.apache.spark.rdd.RDDOperationScope$.withScope(\u001b[32mRDDOperationScope.scala\u001b[39m:\u001b[32m151\u001b[39m)\r\n  org.apache.spark.rdd.RDDOperationScope$.withScope(\u001b[32mRDDOperationScope.scala\u001b[39m:\u001b[32m112\u001b[39m)\r\n  org.apache.spark.rdd.RDD.withScope(\u001b[32mRDD.scala\u001b[39m:\u001b[32m385\u001b[39m)\r\n  org.apache.spark.rdd.DoubleRDDFunctions.histogram(\u001b[32mDoubleRDDFunctions.scala\u001b[39m:\u001b[32m123\u001b[39m)\r\n  ammonite.$sess.cmd9$Helper.<init>(\u001b[32mcmd9.sc\u001b[39m:\u001b[32m2\u001b[39m)\r\n  ammonite.$sess.cmd9$.<init>(\u001b[32mcmd9.sc\u001b[39m:\u001b[32m7\u001b[39m)\r\n  ammonite.$sess.cmd9$.<clinit>(\u001b[32mcmd9.sc\u001b[39m:\u001b[32m-1\u001b[39m)\r\n\u001b[31mjava.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double\u001b[39m\r\n  scala.runtime.BoxesRunTime.unboxToDouble(\u001b[32mBoxesRunTime.java\u001b[39m:\u001b[32m116\u001b[39m)\r\n  ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1(\u001b[32mcmd9.sc\u001b[39m:\u001b[32m2\u001b[39m)\r\n  ammonite.$sess.cmd9$Helper.$anonfun$res9_1$1$adapted(\u001b[32mcmd9.sc\u001b[39m:\u001b[32m2\u001b[39m)\r\n  scala.collection.Iterator$$anon$10.next(\u001b[32mIterator.scala\u001b[39m:\u001b[32m461\u001b[39m)\r\n  scala.collection.Iterator.foreach(\u001b[32mIterator.scala\u001b[39m:\u001b[32m943\u001b[39m)\r\n  scala.collection.Iterator.foreach$(\u001b[32mIterator.scala\u001b[39m:\u001b[32m943\u001b[39m)\r\n  scala.collection.AbstractIterator.foreach(\u001b[32mIterator.scala\u001b[39m:\u001b[32m1431\u001b[39m)\r\n  scala.collection.TraversableOnce.reversed(\u001b[32mTraversableOnce.scala\u001b[39m:\u001b[32m122\u001b[39m)\r\n  scala.collection.TraversableOnce.reversed$(\u001b[32mTraversableOnce.scala\u001b[39m:\u001b[32m117\u001b[39m)\r\n  scala.collection.AbstractIterator.reversed(\u001b[32mIterator.scala\u001b[39m:\u001b[32m1431\u001b[39m)\r\n  scala.collection.TraversableOnce.foldRight(\u001b[32mTraversableOnce.scala\u001b[39m:\u001b[32m194\u001b[39m)\r\n  scala.collection.TraversableOnce.foldRight$(\u001b[32mTraversableOnce.scala\u001b[39m:\u001b[32m193\u001b[39m)\r\n  scala.collection.AbstractIterator.foldRight(\u001b[32mIterator.scala\u001b[39m:\u001b[32m1431\u001b[39m)\r\n  org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$histogram$3(\u001b[32mDoubleRDDFunctions.scala\u001b[39m:\u001b[32m133\u001b[39m)\r\n  org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(\u001b[32mRDD.scala\u001b[39m:\u001b[32m823\u001b[39m)\r\n  org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(\u001b[32mRDD.scala\u001b[39m:\u001b[32m823\u001b[39m)\r\n  org.apache.spark.rdd.MapPartitionsRDD.compute(\u001b[32mMapPartitionsRDD.scala\u001b[39m:\u001b[32m52\u001b[39m)\r\n  org.apache.spark.rdd.RDD.computeOrReadCheckpoint(\u001b[32mRDD.scala\u001b[39m:\u001b[32m346\u001b[39m)\r\n  org.apache.spark.rdd.RDD.iterator(\u001b[32mRDD.scala\u001b[39m:\u001b[32m310\u001b[39m)\r\n  org.apache.spark.scheduler.ResultTask.runTask(\u001b[32mResultTask.scala\u001b[39m:\u001b[32m90\u001b[39m)\r\n  org.apache.spark.scheduler.Task.run(\u001b[32mTask.scala\u001b[39m:\u001b[32m123\u001b[39m)\r\n  org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(\u001b[32mExecutor.scala\u001b[39m:\u001b[32m411\u001b[39m)\r\n  org.apache.spark.util.Utils$.tryWithSafeFinally(\u001b[32mUtils.scala\u001b[39m:\u001b[32m1360\u001b[39m)\r\n  org.apache.spark.executor.Executor$TaskRunner.run(\u001b[32mExecutor.scala\u001b[39m:\u001b[32m414\u001b[39m)\r\n  java.util.concurrent.ThreadPoolExecutor.runWorker(\u001b[32mThreadPoolExecutor.java\u001b[39m:\u001b[32m1149\u001b[39m)\r\n  java.util.concurrent.ThreadPoolExecutor$Worker.run(\u001b[32mThreadPoolExecutor.java\u001b[39m:\u001b[32m624\u001b[39m)\r\n  java.lang.Thread.run(\u001b[32mThread.java\u001b[39m:\u001b[32m748\u001b[39m)"
     ]
    }
   ],
   "source": [
    "// Visualiser la distribution des valeurs pour la colonne Time\n",
    "cb_fraude.select(\"Time\").describe().show()\n",
    "cb_fraude.select(\"Time\").rdd.map(r => r(0).asInstanceOf[Double]).histogram(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9a3cac5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            Amount|\n",
      "+-------+------------------+\n",
      "|  count|            284807|\n",
      "|   mean| 88.34961925093077|\n",
      "| stddev|250.12010924018867|\n",
      "|    min|               0.0|\n",
      "|    max|          25691.16|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+-----------------+\n",
      "|summary|             Time|\n",
      "+-------+-----------------+\n",
      "|  count|           284807|\n",
      "|   mean|       94813.8596|\n",
      "| stddev|47488.14595456596|\n",
      "|    min|                0|\n",
      "|    max|           172792|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 02:31:55 ERROR Executor: Exception in task 0.0 in stage 21.0 (TID 164)\n",
      "java.lang.ClassCastException\n",
      "23/03/25 02:31:55 ERROR Executor: Exception in task 9.0 in stage 21.0 (TID 173)\n",
      "java.lang.ClassCastException\n",
      "23/03/25 02:31:55 ERROR Executor: Exception in task 3.0 in stage 21.0 (TID 167)\n",
      "java.lang.ClassCastException\n",
      "23/03/25 02:31:55 ERROR Executor: Exception in task 1.0 in stage 21.0 (TID 165)\n",
      "java.lang.ClassCastException\n",
      "23/03/25 02:31:55 ERROR Executor: Exception in task 6.0 in stage 21.0 (TID 170)\n",
      "java.lang.ClassCastException\n",
      "23/03/25 02:31:55 ERROR Executor: Exception in task 8.0 in stage 21.0 (TID 172)\n",
      "java.lang.ClassCastException\n",
      "23/03/25 02:31:55 ERROR Executor: Exception in task 10.0 in stage 21.0 (TID 174)\n",
      "java.lang.ClassCastException\n",
      "23/03/25 02:31:55 WARN TaskSetManager: Lost task 0.0 in stage 21.0 (TID 164, localhost, executor driver): java.lang.ClassCastException\n",
      "\n",
      "23/03/25 02:31:55 ERROR Executor: Exception in task 11.0 in stage 21.0 (TID 175)\n",
      "java.lang.ClassCastException\n",
      "23/03/25 02:31:55 ERROR Executor: Exception in task 7.0 in stage 21.0 (TID 171)\n",
      "java.lang.ClassCastException\n",
      "23/03/25 02:31:55 ERROR Executor: Exception in task 2.0 in stage 21.0 (TID 166)\n",
      "java.lang.ClassCastException\n",
      "23/03/25 02:31:55 ERROR Executor: Exception in task 4.0 in stage 21.0 (TID 168)\n",
      "java.lang.ClassCastException\n",
      "23/03/25 02:31:55 ERROR Executor: Exception in task 5.0 in stage 21.0 (TID 169)\n",
      "java.lang.ClassCastException\n",
      "23/03/25 02:31:55 ERROR TaskSetManager: Task 0 in stage 21.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31morg.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 21.0 failed 1 times, most recent failure: Lost task 0.0 in stage 21.0 (TID 164, localhost, executor driver): java.lang.ClassCastException\r\n\nDriver stacktrace:\u001b[39m\r\n  org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m1891\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m1879\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m1878\u001b[39m)\r\n  scala.collection.mutable.ResizableArray.foreach(\u001b[32mResizableArray.scala\u001b[39m:\u001b[32m62\u001b[39m)\r\n  scala.collection.mutable.ResizableArray.foreach$(\u001b[32mResizableArray.scala\u001b[39m:\u001b[32m55\u001b[39m)\r\n  scala.collection.mutable.ArrayBuffer.foreach(\u001b[32mArrayBuffer.scala\u001b[39m:\u001b[32m49\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.abortStage(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m1878\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m927\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m927\u001b[39m)\r\n  scala.Option.foreach(\u001b[32mOption.scala\u001b[39m:\u001b[32m407\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m927\u001b[39m)\r\n  org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m2112\u001b[39m)\r\n  org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m2061\u001b[39m)\r\n  org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m2050\u001b[39m)\r\n  org.apache.spark.util.EventLoop$$anon$1.run(\u001b[32mEventLoop.scala\u001b[39m:\u001b[32m49\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.runJob(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m738\u001b[39m)\r\n  org.apache.spark.SparkContext.runJob(\u001b[32mSparkContext.scala\u001b[39m:\u001b[32m2061\u001b[39m)\r\n  org.apache.spark.SparkContext.runJob(\u001b[32mSparkContext.scala\u001b[39m:\u001b[32m2158\u001b[39m)\r\n  org.apache.spark.rdd.RDD.$anonfun$reduce$1(\u001b[32mRDD.scala\u001b[39m:\u001b[32m1080\u001b[39m)\r\n  org.apache.spark.rdd.RDDOperationScope$.withScope(\u001b[32mRDDOperationScope.scala\u001b[39m:\u001b[32m151\u001b[39m)\r\n  org.apache.spark.rdd.RDDOperationScope$.withScope(\u001b[32mRDDOperationScope.scala\u001b[39m:\u001b[32m112\u001b[39m)\r\n  org.apache.spark.rdd.RDD.withScope(\u001b[32mRDD.scala\u001b[39m:\u001b[32m385\u001b[39m)\r\n  org.apache.spark.rdd.RDD.reduce(\u001b[32mRDD.scala\u001b[39m:\u001b[32m1062\u001b[39m)\r\n  org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$histogram$1(\u001b[32mDoubleRDDFunctions.scala\u001b[39m:\u001b[32m134\u001b[39m)\r\n  org.apache.spark.rdd.RDDOperationScope$.withScope(\u001b[32mRDDOperationScope.scala\u001b[39m:\u001b[32m151\u001b[39m)\r\n  org.apache.spark.rdd.RDDOperationScope$.withScope(\u001b[32mRDDOperationScope.scala\u001b[39m:\u001b[32m112\u001b[39m)\r\n  org.apache.spark.rdd.RDD.withScope(\u001b[32mRDD.scala\u001b[39m:\u001b[32m385\u001b[39m)\r\n  org.apache.spark.rdd.DoubleRDDFunctions.histogram(\u001b[32mDoubleRDDFunctions.scala\u001b[39m:\u001b[32m123\u001b[39m)\r\n  ammonite.$sess.cmd10$Helper.<init>(\u001b[32mcmd10.sc\u001b[39m:\u001b[32m8\u001b[39m)\r\n  ammonite.$sess.cmd10$.<init>(\u001b[32mcmd10.sc\u001b[39m:\u001b[32m7\u001b[39m)\r\n  ammonite.$sess.cmd10$.<clinit>(\u001b[32mcmd10.sc\u001b[39m:\u001b[32m-1\u001b[39m)\r\n\u001b[31mjava.lang.ClassCastException\u001b[39m\r\n"
     ]
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "\n",
    "cb_fraude.select(\"Amount\").describe().show()\n",
    "cb_fraude.select(\"Amount\").rdd.map(r => r(0).asInstanceOf[Double]).histogram(10)\n",
    "\n",
    "// Visualiser la distribution des valeurs pour la colonne Time\n",
    "cb_fraude.select(\"Time\").describe().show()\n",
    "cb_fraude.select(\"Time\").rdd.map(r => r(0).asInstanceOf[Double]).histogram(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02a042c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcb_fraude_clean\u001b[39m: \u001b[32mDataFrame\u001b[39m = [V1: double, V2: double ... 27 more fields]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cb_fraude_clean = cb_fraude.drop(\"Time\", \"Amount\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e588a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainingData\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [V1: double, V2: double ... 27 more fields]\r\n",
       "\u001b[36mtestData\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [V1: double, V2: double ... 27 more fields]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(trainingData, testData) = cb_fraude_clean.randomSplit(Array(0.8, 0.2), seed = 12345)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9187effe",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mselectedFeatures\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mArray\u001b[39m(\n",
       "  \u001b[32m\"V1\"\u001b[39m,\n",
       "  \u001b[32m\"V2\"\u001b[39m,\n",
       "  \u001b[32m\"V3\"\u001b[39m,\n",
       "  \u001b[32m\"V4\"\u001b[39m,\n",
       "  \u001b[32m\"V5\"\u001b[39m,\n",
       "  \u001b[32m\"V6\"\u001b[39m,\n",
       "  \u001b[32m\"V7\"\u001b[39m,\n",
       "  \u001b[32m\"V8\"\u001b[39m,\n",
       "  \u001b[32m\"V9\"\u001b[39m,\n",
       "  \u001b[32m\"V10\"\u001b[39m,\n",
       "  \u001b[32m\"V11\"\u001b[39m,\n",
       "  \u001b[32m\"V12\"\u001b[39m,\n",
       "  \u001b[32m\"V13\"\u001b[39m,\n",
       "  \u001b[32m\"V14\"\u001b[39m,\n",
       "  \u001b[32m\"V15\"\u001b[39m,\n",
       "  \u001b[32m\"V16\"\u001b[39m,\n",
       "  \u001b[32m\"V17\"\u001b[39m,\n",
       "  \u001b[32m\"V18\"\u001b[39m,\n",
       "  \u001b[32m\"V19\"\u001b[39m,\n",
       "  \u001b[32m\"V20\"\u001b[39m,\n",
       "  \u001b[32m\"V21\"\u001b[39m,\n",
       "  \u001b[32m\"V22\"\u001b[39m,\n",
       "  \u001b[32m\"V23\"\u001b[39m,\n",
       "  \u001b[32m\"V24\"\u001b[39m,\n",
       "  \u001b[32m\"V25\"\u001b[39m,\n",
       "  \u001b[32m\"V26\"\u001b[39m,\n",
       "  \u001b[32m\"V27\"\u001b[39m,\n",
       "  \u001b[32m\"V28\"\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Sélection des caractéristiques pertinentes pour la détection de la fraude\n",
    "val selectedFeatures = cb_fraude_clean.columns.filter(_ != \"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "377213fe",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.ml.feature.VectorAssembler\n",
       "\n",
       "\u001b[39m\r\n",
       "\u001b[36massembler\u001b[39m: \u001b[32mVectorAssembler\u001b[39m = vecAssembler_870089248606\r\n",
       "\u001b[36massembledTrainingData\u001b[39m: \u001b[32mDataFrame\u001b[39m = [V1: double, V2: double ... 28 more fields]\r\n",
       "\u001b[36massembledTestData\u001b[39m: \u001b[32mDataFrame\u001b[39m = [V1: double, V2: double ... 28 more fields]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Assemblage des caractéristiques en un vecteur de fonctionnalités\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "\n",
    "val assembler = new VectorAssembler()\n",
    ".setInputCols(selectedFeatures)\n",
    ".setOutputCol(\"features\")\n",
    "\n",
    "val assembledTrainingData = assembler.transform(trainingData)\n",
    "val assembledTestData = assembler.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ee6e51",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+----------------+-----------------+----------------+-----------------+------------------+-----------------+-----------------+-----------------+-----------------+----------------+----------------+-----------------+-----------------+-----------------+----------------+------------------+----------------+-----------------+-----+--------------------+\n",
      "|               V1|              V2|               V3|              V4|               V5|               V6|               V7|              V8|               V9|              V10|             V11|              V12|             V13|              V14|               V15|              V16|              V17|              V18|              V19|             V20|             V21|              V22|              V23|              V24|             V25|               V26|             V27|              V28|Class|            features|\n",
      "+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+----------------+-----------------+----------------+-----------------+------------------+-----------------+-----------------+-----------------+-----------------+----------------+----------------+-----------------+-----------------+-----------------+----------------+------------------+----------------+-----------------+-----+--------------------+\n",
      "| -30.552380043581|16.7133892350242|-31.1036848245812|6.53498386355181| -22.105531524316|-4.97769196369245| -20.371513594495|20.0072083651213|-3.56573779124378| -7.7310714411342| 3.8294273949908|-5.31433227604015|1.44693027992913|-4.57926372815218|-0.142299360010106|-4.99784830436345|-10.9614103561188|-4.64148195920404|0.567056279787444|1.73364399368955| 1.8165201713562|-2.28868550494101|-1.46054449877578|0.183179482716819|2.20820917836653|-0.208823971247713|1.23263629519904|0.356660010884047|    1|[-30.552380043581...|\n",
      "|-29.8763655139763|16.4345245512223|-30.5586968214292|6.50586178736296|-21.6656542956569|-4.94035632949796|-20.0813910746494|19.5877726234404|-3.59149104711596|-7.80059820772759|3.94783971729026| -5.4879114860488|1.36994034924206|-4.82955244300835|-0.134412095441135|-5.12116240451142|-11.1181904509172|-4.65995586983801|0.608930080519071|1.72477883837961|1.81295397464878|-2.23225158753151|-1.41280344282556|0.178731069561437|2.15604185816706| -0.20938462411377|1.25564890085966|0.364530452975509|    1|[-29.876365513976...|\n",
      "|-29.2003285905744|16.1557014298057|-30.0137124857248|6.47673117996833|-21.2258096535165|-4.90299739658728| -19.791248405247|19.1683273897301|-3.61724178604255|-7.87012194292549|4.06625507293473|-5.66149242261771|1.29295014454242|-5.07984568135779|-0.126522740416921|-5.24447151974264|-11.2749725851252|-4.67843652929376|0.650807370688892|1.71586182428358| 1.8093709332884|-2.17581520342142| -1.3651041075509|0.174286359566544|2.10386807204715|-0.209943999130567|1.27868097084218|0.372392714338541|    1|[-29.200328590574...|\n",
      "|-28.5242675938406|15.8769229879536|-29.4687320925264|6.44759140152748|-20.7860000418837|-4.86561341755669|-19.5010840750712|18.7488719520883|-3.64298981925263|-7.93964241937325|4.18467368942509|-5.83507521523889|1.21595964527928|-5.33014378246253|-0.118631138153322|-5.36777527618834|-11.4317569116986|-4.69692444373293| 0.69268841200477| 1.7068890619925|1.80576978392608|-2.11937616760819|-1.31744962200248|0.169845630469178|2.05168733506275|-0.210502000459411|1.30173396497076|0.380246181418509|    1|[-28.524267593840...|\n",
      "|  -27.84818067198|15.5981926625554| -28.923755945104|6.41844174657532| -20.346228155413|-4.82820246578157|-19.2108964179086| 18.329405525597|-3.66873493861418|-8.00915938639777|4.30309581759563|-6.00866000668561| 1.1389688287939|-5.58044712038062| -0.11073711578577|-5.49107326163426|-11.5885435992809|-4.71542017123115|0.734573493016404|1.69785626318366| 1.8021491336386|-2.06293427611466|-1.26984343615924|0.165409188492223|1.99949911253199|-0.211058522431997|1.32480949279508|0.388090177732107|    1|[-27.84818067198,...|\n",
      "+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+----------------+-----------------+----------------+-----------------+------------------+-----------------+-----------------+-----------------+-----------------+----------------+----------------+-----------------+-----------------+-----------------+----------------+------------------+----------------+-----------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Affichage des premières lignes du DataFrame après assemblage des caractéristiques\n",
    "assembledTrainingData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19f8b3e6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud count in training set: 392\n",
      "Fraud count in test set: 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mfraudCountTraining\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m392L\u001b[39m\r\n",
       "\u001b[36mfraudCountTest\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m100L\u001b[39m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Affichage du nombre de transactions frauduleuses dans les ensembles d'entraînement et de test\n",
    "val fraudCountTraining = assembledTrainingData.filter(col(\"Class\") === 1).count()\n",
    "val fraudCountTest = assembledTestData.filter(col(\"Class\") === 1).count()\n",
    "println(s\"Fraud count in training set: $fraudCountTraining\")\n",
    "println(s\"Fraud count in test set: $fraudCountTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1405366c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.ml.classification.LogisticRegression\n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.ml.feature.VectorAssembler\n",
       "\n",
       "// Définir le modèle de régression logistique\n",
       "\u001b[39m\r\n",
       "\u001b[36mlr\u001b[39m: \u001b[32mLogisticRegression\u001b[39m = logreg_21d460923de0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "\n",
    "// Définir le modèle de régression logistique\n",
    "val lr = new LogisticRegression()\n",
    ".setLabelCol(\"Class\")\n",
    ".setFeaturesCol(\"features\")\n",
    ".setMaxIter(10)\n",
    ".setRegParam(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28cc3b4a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 02:47:55 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "23/03/25 02:47:55 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "23/03/25 02:47:55 INFO LBFGS: Step Size: 33,69\n",
      "23/03/25 02:47:55 INFO LBFGS: Val and Grad Norm: 0,00712340 (rel: 0,438) 0,00515942\n",
      "23/03/25 02:47:55 INFO LBFGS: Step Size: 1,500\n",
      "23/03/25 02:47:55 INFO LBFGS: Val and Grad Norm: 0,00609361 (rel: 0,145) 0,00442296\n",
      "23/03/25 02:47:55 INFO StrongWolfeLineSearch: Line search t: 0.12429927106991745 fval: 0.005391720278673216 rhs: 0.006093534241055226 cdd: -0.004799561857795579\n",
      "23/03/25 02:47:55 INFO LBFGS: Step Size: 0,1243\n",
      "23/03/25 02:47:55 INFO LBFGS: Val and Grad Norm: 0,00539172 (rel: 0,115) 0,00328031\n",
      "23/03/25 02:47:55 INFO StrongWolfeLineSearch: Line search t: 0.48046815670602994 fval: 0.004682390839816084 rhs: 0.0053916120304223 cdd: -9.567224902772836E-5\n",
      "23/03/25 02:47:55 INFO LBFGS: Step Size: 0,4805\n",
      "23/03/25 02:47:55 INFO LBFGS: Val and Grad Norm: 0,00468239 (rel: 0,132) 0,00141876\n",
      "23/03/25 02:47:55 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 02:47:55 INFO LBFGS: Val and Grad Norm: 0,00456329 (rel: 0,0254) 0,00145630\n",
      "23/03/25 02:47:55 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 02:47:55 INFO LBFGS: Val and Grad Norm: 0,00421189 (rel: 0,0770) 0,00155692\n",
      "23/03/25 02:47:55 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 02:47:55 INFO LBFGS: Val and Grad Norm: 0,00405573 (rel: 0,0371) 0,000702782\n",
      "23/03/25 02:47:55 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 02:47:55 INFO LBFGS: Val and Grad Norm: 0,00398900 (rel: 0,0165) 0,000585318\n",
      "23/03/25 02:47:55 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 02:47:55 INFO LBFGS: Val and Grad Norm: 0,00398550 (rel: 0,000876) 0,00160863\n",
      "23/03/25 02:47:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 02:47:56 INFO LBFGS: Val and Grad Norm: 0,00389692 (rel: 0,0222) 0,000324725\n",
      "23/03/25 02:47:56 INFO LBFGS: Converged because max iterations reached\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mmodel\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mml\u001b[39m.\u001b[32mclassification\u001b[39m.\u001b[32mLogisticRegressionModel\u001b[39m = LogisticRegressionModel: uid = logreg_21d460923de0, numClasses = 2, numFeatures = 28"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Entraîner le modèle avec les données d'entraînement\n",
    "val model = lr.fit(assembledTrainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23a8b376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mpredictions\u001b[39m: \u001b[32mDataFrame\u001b[39m = [V1: double, V2: double ... 31 more fields]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Faire des prédictions sur les données de test\n",
    "val predictions = model.transform(assembledTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d72fb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC: 0.9705417184464492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mevaluator\u001b[39m: \u001b[32mBinaryClassificationEvaluator\u001b[39m = binEval_88863866907c\r\n",
       "\u001b[36mareaUnderROC\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.9705417184464492\u001b[39m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Évaluer la performance du modèle à l'aide de l'évaluateur d'évaluation de classification binaire\n",
    "val evaluator = new BinaryClassificationEvaluator()\n",
    ".setLabelCol(\"Class\")\n",
    ".setRawPredictionCol(\"rawPrediction\")\n",
    ".setMetricName(\"areaUnderROC\")\n",
    "val areaUnderROC = evaluator.evaluate(predictions)\n",
    "println(s\"Area under ROC: $areaUnderROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb6da94d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|Class|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|    0|[-28.344757250015...|\n",
      "|       0.0|    1|[-27.143678422949...|\n",
      "|       1.0|    0|[-26.619952145208...|\n",
      "|       0.0|    0|[-23.066841657925...|\n",
      "|       1.0|    1|[-22.561699259129...|\n",
      "|       1.0|    1|[-21.885433905174...|\n",
      "|       1.0|    1|[-15.819178720771...|\n",
      "|       1.0|    0|[-15.239439628061...|\n",
      "|       1.0|    1|[-14.724627011925...|\n",
      "|       0.0|    0|[-14.138924695625...|\n",
      "|       0.0|    0|[-13.583082802692...|\n",
      "|       0.0|    0|[-12.504075025054...|\n",
      "|       0.0|    0|[-12.229230892692...|\n",
      "|       0.0|    0|[-12.216458689092...|\n",
      "|       0.0|    0|[-12.156495081502...|\n",
      "|       0.0|    0|[-11.840668989052...|\n",
      "|       0.0|    0|[-11.781028386318...|\n",
      "|       0.0|    0|[-11.429498678806...|\n",
      "|       0.0|    0|[-11.117454709763...|\n",
      "|       0.0|    0|[-10.648382319781...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Afficher les prédictions avec la vraie valeur de la classe\n",
    "predictions.select(\"prediction\", \"Class\", \"features\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "911995f3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 02:50:34 INFO LBFGS: Step Size: 33,69\n",
      "23/03/25 02:50:34 INFO LBFGS: Val and Grad Norm: 0,00712340 (rel: 0,438) 0,00515942\n",
      "23/03/25 02:50:34 INFO LBFGS: Step Size: 1,500\n",
      "23/03/25 02:50:34 INFO LBFGS: Val and Grad Norm: 0,00609361 (rel: 0,145) 0,00442296\n",
      "23/03/25 02:50:34 INFO StrongWolfeLineSearch: Line search t: 0.12429927106991767 fval: 0.005391720278673216 rhs: 0.0060935342410552255 cdd: -0.004799561857795575\n",
      "23/03/25 02:50:34 INFO LBFGS: Step Size: 0,1243\n",
      "23/03/25 02:50:34 INFO LBFGS: Val and Grad Norm: 0,00539172 (rel: 0,115) 0,00328031\n",
      "23/03/25 02:50:34 INFO StrongWolfeLineSearch: Line search t: 0.4804681567060298 fval: 0.0046823908398160845 rhs: 0.0053916120304223 cdd: -9.567224902773055E-5\n",
      "23/03/25 02:50:34 INFO LBFGS: Step Size: 0,4805\n",
      "23/03/25 02:50:34 INFO LBFGS: Val and Grad Norm: 0,00468239 (rel: 0,132) 0,00141876\n",
      "23/03/25 02:50:34 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 02:50:34 INFO LBFGS: Val and Grad Norm: 0,00456329 (rel: 0,0254) 0,00145630\n",
      "23/03/25 02:50:34 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 02:50:34 INFO LBFGS: Val and Grad Norm: 0,00421189 (rel: 0,0770) 0,00155692\n",
      "23/03/25 02:50:35 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 02:50:35 INFO LBFGS: Val and Grad Norm: 0,00405573 (rel: 0,0371) 0,000702782\n",
      "23/03/25 02:50:35 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 02:50:35 INFO LBFGS: Val and Grad Norm: 0,00398900 (rel: 0,0165) 0,000585318\n",
      "23/03/25 02:50:35 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 02:50:35 INFO LBFGS: Val and Grad Norm: 0,00398550 (rel: 0,000876) 0,00160863\n",
      "23/03/25 02:50:35 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 02:50:35 INFO LBFGS: Val and Grad Norm: 0,00389692 (rel: 0,0222) 0,000324725\n",
      "23/03/25 02:50:35 INFO LBFGS: Converged because max iterations reached\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
       "\n",
       "\u001b[39m\r\n",
       "\u001b[36mlrModel\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mml\u001b[39m.\u001b[32mclassification\u001b[39m.\u001b[32mLogisticRegressionModel\u001b[39m = LogisticRegressionModel: uid = logreg_21d460923de0, numClasses = 2, numFeatures = 28\r\n",
       "\u001b[36mpredictions\u001b[39m: \u001b[32mDataFrame\u001b[39m = [V1: double, V2: double ... 31 more fields]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "\n",
    "val lrModel = lr.fit(assembledTrainingData)\n",
    "\n",
    "val predictions = lrModel.transform(assembledTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dccdb7f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|Class|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|    0|[-28.344757250015...|\n",
      "|       0.0|    1|[-27.143678422949...|\n",
      "|       1.0|    0|[-26.619952145208...|\n",
      "|       0.0|    0|[-23.066841657925...|\n",
      "|       1.0|    1|[-22.561699259129...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Area under ROC: 0.9705417184464595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mevaluator\u001b[39m: \u001b[32mBinaryClassificationEvaluator\u001b[39m = binEval_393efbe661ec\r\n",
       "\u001b[36mareaUnderROC\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.9705417184464595\u001b[39m"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Afficher les résultats de la prédiction\n",
    "predictions.select(\"prediction\", \"Class\", \"features\").show(5)\n",
    "\n",
    "val evaluator = new BinaryClassificationEvaluator()\n",
    ".setLabelCol(\"Class\")\n",
    ".setRawPredictionCol(\"rawPrediction\")\n",
    ".setMetricName(\"areaUnderROC\")\n",
    "\n",
    "val areaUnderROC = evaluator.evaluate(predictions)\n",
    "println(s\"Area under ROC: ${areaUnderROC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fadef62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions.col\n",
       "\n",
       "\u001b[39m\r\n",
       "\u001b[36mpredictionAndLabels\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mrdd\u001b[39m.\u001b[32mRDD\u001b[39m[(\u001b[32mDouble\u001b[39m, \u001b[32mDouble\u001b[39m)] = MapPartitionsRDD[436] at map at cmd43.sc:5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Essayez de convertir ces colonnes en Double en utilisant la fonction \"cast\" de Spark SQL :\n",
    "import org.apache.spark.sql.functions.col\n",
    "\n",
    "val predictionAndLabels = predictions.select(col(\"prediction\").cast(\"Double\"), col(\"Class\").cast(\"Double\"))\n",
    "  .rdd\n",
    "  .map(row => (row.getDouble(0), row.getDouble(1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d19d2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mpredictionAndLabels\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mrdd\u001b[39m.\u001b[32mRDD\u001b[39m[(\u001b[32mDouble\u001b[39m, \u001b[32mDouble\u001b[39m)] = MapPartitionsRDD[424] at map at cmd38.sc:5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictionAndLabels = predictions.select(\"prediction\", \"Class\")\n",
    "  .withColumn(\"predictionDouble\", $\"prediction\".cast(DoubleType))\n",
    "  .withColumn(\"classDouble\", $\"Class\".cast(DoubleType))\n",
    "  .rdd\n",
    "  .map(row => (row.getAs[Double](\"predictionDouble\"), row.getAs[Double](\"classDouble\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63317290",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "57120.0  13.0  \n",
      "33.0     67.0  \n",
      "Precision: 0.8375\n",
      "Recall: 0.67\n",
      "F1-score: 0.7444444444444446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.mllib.evaluation.MulticlassMetrics\n",
       "\n",
       "\u001b[39m\r\n",
       "\u001b[36mpredictionAndLabels\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mrdd\u001b[39m.\u001b[32mRDD\u001b[39m[(\u001b[32mDouble\u001b[39m, \u001b[32mDouble\u001b[39m)] = MapPartitionsRDD[442] at map at cmd44.sc:5\r\n",
       "\u001b[36mmetrics\u001b[39m: \u001b[32mMulticlassMetrics\u001b[39m = org.apache.spark.mllib.evaluation.MulticlassMetrics@702a07be\r\n",
       "\u001b[36mprecision\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.8375\u001b[39m\r\n",
       "\u001b[36mrecall\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.67\u001b[39m\r\n",
       "\u001b[36mf1Score\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.7444444444444446\u001b[39m"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics\n",
    "\n",
    "val predictionAndLabels = predictions.selectExpr(\"cast(prediction as double)\", \"cast(Class as double)\")\n",
    "  .rdd\n",
    "  .map(row => (row.getDouble(0), row.getDouble(1)))\n",
    "\n",
    "val metrics = new MulticlassMetrics(predictionAndLabels)\n",
    "println(s\"Confusion matrix:\\n${metrics.confusionMatrix}\")\n",
    "\n",
    "val precision = metrics.precision(1.0)\n",
    "val recall = metrics.recall(1.0)\n",
    "val f1Score = metrics.fMeasure(1.0)\n",
    "\n",
    "println(s\"Precision: $precision\")\n",
    "println(s\"Recall: $recall\")\n",
    "println(s\"F1-score: $f1Score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8293fb46",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 03:17:57 ERROR Executor: Exception in task 4.0 in stage 148.0 (TID 1078)\n",
      "org.apache.spark.SparkException: Chi-square test expect factors (categorical values) but found more than 10000 distinct values in column 0.\n",
      "\tat org.apache.spark.mllib.stat.test.ChiSqTest$.$anonfun$chiSquaredFeatures$4(ChiSqTest.scala:111)\n",
      "\tat org.apache.spark.mllib.stat.test.ChiSqTest$.$anonfun$chiSquaredFeatures$4$adapted(ChiSqTest.scala:108)\n",
      "\tat scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:370)\n",
      "\tat scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:675)\n",
      "\tat org.apache.spark.mllib.stat.test.ChiSqTest$.$anonfun$chiSquaredFeatures$3(ChiSqTest.scala:108)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "23/03/25 03:17:57 WARN TaskSetManager: Lost task 4.0 in stage 148.0 (TID 1078, localhost, executor driver): org.apache.spark.SparkException: Chi-square test expect factors (categorical values) but found more than 10000 distinct values in column 0.\n",
      "\tat org.apache.spark.mllib.stat.test.ChiSqTest$.$anonfun$chiSquaredFeatures$4(ChiSqTest.scala:111)\n",
      "\tat org.apache.spark.mllib.stat.test.ChiSqTest$.$anonfun$chiSquaredFeatures$4$adapted(ChiSqTest.scala:108)\n",
      "\tat scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:370)\n",
      "\tat scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:675)\n",
      "\tat org.apache.spark.mllib.stat.test.ChiSqTest$.$anonfun$chiSquaredFeatures$3(ChiSqTest.scala:108)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "23/03/25 03:17:57 ERROR TaskSetManager: Task 4 in stage 148.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31morg.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 148.0 failed 1 times, most recent failure: Lost task 4.0 in stage 148.0 (TID 1078, localhost, executor driver): org.apache.spark.SparkException: Chi-square test expect factors (categorical values) but found more than 10000 distinct values in column 0.\r\n\tat org.apache.spark.mllib.stat.test.ChiSqTest$.$anonfun$chiSquaredFeatures$4(ChiSqTest.scala:111)\r\n\tat org.apache.spark.mllib.stat.test.ChiSqTest$.$anonfun$chiSquaredFeatures$4$adapted(ChiSqTest.scala:108)\r\n\tat scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:370)\r\n\tat scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:675)\r\n\tat org.apache.spark.mllib.stat.test.ChiSqTest$.$anonfun$chiSquaredFeatures$3(ChiSqTest.scala:108)\r\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\u001b[39m\r\n  org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m1891\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m1879\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m1878\u001b[39m)\r\n  scala.collection.mutable.ResizableArray.foreach(\u001b[32mResizableArray.scala\u001b[39m:\u001b[32m62\u001b[39m)\r\n  scala.collection.mutable.ResizableArray.foreach$(\u001b[32mResizableArray.scala\u001b[39m:\u001b[32m55\u001b[39m)\r\n  scala.collection.mutable.ArrayBuffer.foreach(\u001b[32mArrayBuffer.scala\u001b[39m:\u001b[32m49\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.abortStage(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m1878\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m927\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m927\u001b[39m)\r\n  scala.Option.foreach(\u001b[32mOption.scala\u001b[39m:\u001b[32m407\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m927\u001b[39m)\r\n  org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m2112\u001b[39m)\r\n  org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m2061\u001b[39m)\r\n  org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m2050\u001b[39m)\r\n  org.apache.spark.util.EventLoop$$anon$1.run(\u001b[32mEventLoop.scala\u001b[39m:\u001b[32m49\u001b[39m)\r\n  org.apache.spark.scheduler.DAGScheduler.runJob(\u001b[32mDAGScheduler.scala\u001b[39m:\u001b[32m738\u001b[39m)\r\n  org.apache.spark.SparkContext.runJob(\u001b[32mSparkContext.scala\u001b[39m:\u001b[32m2061\u001b[39m)\r\n  org.apache.spark.SparkContext.runJob(\u001b[32mSparkContext.scala\u001b[39m:\u001b[32m2082\u001b[39m)\r\n  org.apache.spark.SparkContext.runJob(\u001b[32mSparkContext.scala\u001b[39m:\u001b[32m2101\u001b[39m)\r\n  org.apache.spark.SparkContext.runJob(\u001b[32mSparkContext.scala\u001b[39m:\u001b[32m2126\u001b[39m)\r\n  org.apache.spark.rdd.RDD.$anonfun$collect$1(\u001b[32mRDD.scala\u001b[39m:\u001b[32m990\u001b[39m)\r\n  org.apache.spark.rdd.RDDOperationScope$.withScope(\u001b[32mRDDOperationScope.scala\u001b[39m:\u001b[32m151\u001b[39m)\r\n  org.apache.spark.rdd.RDDOperationScope$.withScope(\u001b[32mRDDOperationScope.scala\u001b[39m:\u001b[32m112\u001b[39m)\r\n  org.apache.spark.rdd.RDD.withScope(\u001b[32mRDD.scala\u001b[39m:\u001b[32m385\u001b[39m)\r\n  org.apache.spark.rdd.RDD.collect(\u001b[32mRDD.scala\u001b[39m:\u001b[32m989\u001b[39m)\r\n  org.apache.spark.rdd.PairRDDFunctions.$anonfun$countByKey$1(\u001b[32mPairRDDFunctions.scala\u001b[39m:\u001b[32m370\u001b[39m)\r\n  org.apache.spark.rdd.RDDOperationScope$.withScope(\u001b[32mRDDOperationScope.scala\u001b[39m:\u001b[32m151\u001b[39m)\r\n  org.apache.spark.rdd.RDDOperationScope$.withScope(\u001b[32mRDDOperationScope.scala\u001b[39m:\u001b[32m112\u001b[39m)\r\n  org.apache.spark.rdd.RDD.withScope(\u001b[32mRDD.scala\u001b[39m:\u001b[32m385\u001b[39m)\r\n  org.apache.spark.rdd.PairRDDFunctions.countByKey(\u001b[32mPairRDDFunctions.scala\u001b[39m:\u001b[32m370\u001b[39m)\r\n  org.apache.spark.rdd.RDD.$anonfun$countByValue$1(\u001b[32mRDD.scala\u001b[39m:\u001b[32m1259\u001b[39m)\r\n  org.apache.spark.rdd.RDDOperationScope$.withScope(\u001b[32mRDDOperationScope.scala\u001b[39m:\u001b[32m151\u001b[39m)\r\n  org.apache.spark.rdd.RDDOperationScope$.withScope(\u001b[32mRDDOperationScope.scala\u001b[39m:\u001b[32m112\u001b[39m)\r\n  org.apache.spark.rdd.RDD.withScope(\u001b[32mRDD.scala\u001b[39m:\u001b[32m385\u001b[39m)\r\n  org.apache.spark.rdd.RDD.countByValue(\u001b[32mRDD.scala\u001b[39m:\u001b[32m1259\u001b[39m)\r\n  org.apache.spark.mllib.stat.test.ChiSqTest$.chiSquaredFeatures(\u001b[32mChiSqTest.scala\u001b[39m:\u001b[32m124\u001b[39m)\r\n  org.apache.spark.mllib.stat.Statistics$.chiSqTest(\u001b[32mStatistics.scala\u001b[39m:\u001b[32m176\u001b[39m)\r\n  org.apache.spark.mllib.feature.ChiSqSelector.fit(\u001b[32mChiSqSelector.scala\u001b[39m:\u001b[32m258\u001b[39m)\r\n  org.apache.spark.ml.feature.ChiSqSelector.fit(\u001b[32mChiSqSelector.scala\u001b[39m:\u001b[32m214\u001b[39m)\r\n  ammonite.$sess.cmd45$Helper.<init>(\u001b[32mcmd45.sc\u001b[39m:\u001b[32m9\u001b[39m)\r\n  ammonite.$sess.cmd45$.<init>(\u001b[32mcmd45.sc\u001b[39m:\u001b[32m7\u001b[39m)\r\n  ammonite.$sess.cmd45$.<clinit>(\u001b[32mcmd45.sc\u001b[39m:\u001b[32m-1\u001b[39m)\r\n\u001b[31morg.apache.spark.SparkException: Chi-square test expect factors (categorical values) but found more than 10000 distinct values in column 0.\u001b[39m\r\n  org.apache.spark.mllib.stat.test.ChiSqTest$.$anonfun$chiSquaredFeatures$4(\u001b[32mChiSqTest.scala\u001b[39m:\u001b[32m111\u001b[39m)\r\n  org.apache.spark.mllib.stat.test.ChiSqTest$.$anonfun$chiSquaredFeatures$4$adapted(\u001b[32mChiSqTest.scala\u001b[39m:\u001b[32m108\u001b[39m)\r\n  scala.collection.immutable.HashMap$HashMap1.foreach(\u001b[32mHashMap.scala\u001b[39m:\u001b[32m370\u001b[39m)\r\n  scala.collection.immutable.HashMap$HashTrieMap.foreach(\u001b[32mHashMap.scala\u001b[39m:\u001b[32m675\u001b[39m)\r\n  org.apache.spark.mllib.stat.test.ChiSqTest$.$anonfun$chiSquaredFeatures$3(\u001b[32mChiSqTest.scala\u001b[39m:\u001b[32m108\u001b[39m)\r\n  scala.collection.Iterator$$anon$11.nextCur(\u001b[32mIterator.scala\u001b[39m:\u001b[32m486\u001b[39m)\r\n  scala.collection.Iterator$$anon$11.hasNext(\u001b[32mIterator.scala\u001b[39m:\u001b[32m492\u001b[39m)\r\n  scala.collection.Iterator$$anon$10.hasNext(\u001b[32mIterator.scala\u001b[39m:\u001b[32m460\u001b[39m)\r\n  scala.collection.Iterator$$anon$10.hasNext(\u001b[32mIterator.scala\u001b[39m:\u001b[32m460\u001b[39m)\r\n  org.apache.spark.util.collection.ExternalSorter.insertAll(\u001b[32mExternalSorter.scala\u001b[39m:\u001b[32m191\u001b[39m)\r\n  org.apache.spark.shuffle.sort.SortShuffleWriter.write(\u001b[32mSortShuffleWriter.scala\u001b[39m:\u001b[32m62\u001b[39m)\r\n  org.apache.spark.scheduler.ShuffleMapTask.runTask(\u001b[32mShuffleMapTask.scala\u001b[39m:\u001b[32m99\u001b[39m)\r\n  org.apache.spark.scheduler.ShuffleMapTask.runTask(\u001b[32mShuffleMapTask.scala\u001b[39m:\u001b[32m55\u001b[39m)\r\n  org.apache.spark.scheduler.Task.run(\u001b[32mTask.scala\u001b[39m:\u001b[32m123\u001b[39m)\r\n  org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(\u001b[32mExecutor.scala\u001b[39m:\u001b[32m411\u001b[39m)\r\n  org.apache.spark.util.Utils$.tryWithSafeFinally(\u001b[32mUtils.scala\u001b[39m:\u001b[32m1360\u001b[39m)\r\n  org.apache.spark.executor.Executor$TaskRunner.run(\u001b[32mExecutor.scala\u001b[39m:\u001b[32m414\u001b[39m)\r\n  java.util.concurrent.ThreadPoolExecutor.runWorker(\u001b[32mThreadPoolExecutor.java\u001b[39m:\u001b[32m1149\u001b[39m)\r\n  java.util.concurrent.ThreadPoolExecutor$Worker.run(\u001b[32mThreadPoolExecutor.java\u001b[39m:\u001b[32m624\u001b[39m)\r\n  java.lang.Thread.run(\u001b[32mThread.java\u001b[39m:\u001b[32m748\u001b[39m)"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.ChiSqSelector\n",
    "\n",
    "val selector = new ChiSqSelector()\n",
    "  .setFeaturesCol(\"features\")\n",
    "  .setLabelCol(\"Class\")\n",
    "  .setOutputCol(\"selectedFeatures\")\n",
    "  .setNumTopFeatures(10)\n",
    "\n",
    "val model = selector.fit(assembledTrainingData)\n",
    "\n",
    "val selectedTrainingData = model.transform(assembledTrainingData)\n",
    "val selectedTestData = model.transform(assembledTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b9b907e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}\n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
       "\n",
       "// Créer un évaluateur de classification binaire\n",
       "\u001b[39m\r\n",
       "\u001b[36mevaluator\u001b[39m: \u001b[32mBinaryClassificationEvaluator\u001b[39m = binEval_c6dad3addf01"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "\n",
    "// Créer un évaluateur de classification binaire\n",
    "val evaluator = new BinaryClassificationEvaluator()\n",
    "  .setLabelCol(\"Class\")\n",
    "  .setRawPredictionCol(\"rawPrediction\")\n",
    "  .setMetricName(\"areaUnderROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42d8ba72",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mparamGrid\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mml\u001b[39m.\u001b[32mparam\u001b[39m.\u001b[32mParamMap\u001b[39m] = \u001b[33mArray\u001b[39m(\n",
       "  {\n",
       "\tlogreg_21d460923de0-elasticNetParam: 0.0,\n",
       "\tlogreg_21d460923de0-maxIter: 10,\n",
       "\tlogreg_21d460923de0-regParam: 0.01\n",
       "},\n",
       "  {\n",
       "\tlogreg_21d460923de0-elasticNetParam: 0.0,\n",
       "\tlogreg_21d460923de0-maxIter: 10,\n",
       "\tlogreg_21d460923de0-regParam: 0.1\n",
       "},\n",
       "  {\n",
       "\tlogreg_21d460923de0-elasticNetParam: 0.0,\n",
       "\tlogreg_21d460923de0-maxIter: 10,\n",
       "\tlogreg_21d460923de0-regParam: 1.0\n",
       "},\n",
       "  {\n",
       "\tlogreg_21d460923de0-elasticNetParam: 0.5,\n",
       "\tlogreg_21d460923de0-maxIter: 10,\n",
       "\tlogreg_21d460923de0-regParam: 0.01\n",
       "},\n",
       "  {\n",
       "\tlogreg_21d460923de0-elasticNetParam: 0.5,\n",
       "\tlogreg_21d460923de0-maxIter: 10,\n",
       "\tlogreg_21d460923de0-regParam: 0.1\n",
       "},\n",
       "  {\n",
       "\tlogreg_21d460923de0-elasticNetParam: 0.5,\n",
       "\tlogreg_21d460923de0-maxIter: 10,\n",
       "\tlogreg_21d460923de0-regParam: 1.0\n",
       "},\n",
       "  {\n",
       "\tlogreg_21d460923de0-elasticNetParam: 1.0,\n",
       "\tlogreg_21d460923de0-maxIter: 10,\n",
       "\tlogreg_21d460923de0-regParam: 0.01\n",
       "},\n",
       "  {\n",
       "\tlogreg_21d460923de0-elasticNetParam: 1.0,\n",
       "\tlogreg_21d460923de0-maxIter: 10,\n",
       "..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Créer un objet Grid Search pour explorer différentes combinaisons d'hyperparamètres\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "  .addGrid(lr.regParam, Array(0.01, 0.1, 1.0))\n",
    "  .addGrid(lr.elasticNetParam, Array(0.0, 0.5, 1.0))\n",
    "  .addGrid(lr.maxIter, Array(10, 20, 30))\n",
    "  .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3bdee009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcv\u001b[39m: \u001b[32mCrossValidator\u001b[39m = cv_971407aa8bff"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Créer un objet Cross Validator pour évaluer les performances du modèle\n",
    "val cv = new CrossValidator()\n",
    "  .setEstimator(lr)\n",
    "  .setEvaluator(evaluator)\n",
    "  .setEstimatorParamMaps(paramGrid)\n",
    "  .setNumFolds(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a646c189",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 03:24:47 INFO LBFGS: Step Size: 35,75\n",
      "23/03/25 03:24:47 INFO LBFGS: Val and Grad Norm: 0,0111986 (rel: 0,0864) 0,0139599\n",
      "23/03/25 03:24:48 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:48 INFO LBFGS: Val and Grad Norm: 0,00739919 (rel: 0,339) 0,00852427\n",
      "23/03/25 03:24:48 INFO StrongWolfeLineSearch: Line search t: 0.5462093482239323 fval: 0.006034047851508111 rhs: 0.007398941802148653 cdd: -3.810374036990983E-5\n",
      "23/03/25 03:24:48 INFO LBFGS: Step Size: 0,5462\n",
      "23/03/25 03:24:48 INFO LBFGS: Val and Grad Norm: 0,00603405 (rel: 0,184) 0,00171503\n",
      "23/03/25 03:24:48 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:48 INFO LBFGS: Val and Grad Norm: 0,00595802 (rel: 0,0126) 0,00107296\n",
      "23/03/25 03:24:48 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:48 INFO LBFGS: Val and Grad Norm: 0,00588022 (rel: 0,0131) 0,000744475\n",
      "23/03/25 03:24:48 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:48 INFO LBFGS: Val and Grad Norm: 0,00583021 (rel: 0,00851) 0,000821299\n",
      "23/03/25 03:24:48 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:48 INFO LBFGS: Val and Grad Norm: 0,00573357 (rel: 0,0166) 0,000606525\n",
      "23/03/25 03:24:48 INFO StrongWolfeLineSearch: Line search t: 0.2161729614068848 fval: 0.005724419239254126 rhs: 0.005733571829132323 cdd: 9.175163340291175E-6\n",
      "23/03/25 03:24:48 INFO LBFGS: Step Size: 0,2162\n",
      "23/03/25 03:24:48 INFO LBFGS: Val and Grad Norm: 0,00572442 (rel: 0,00160) 0,000421979\n",
      "23/03/25 03:24:48 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:48 INFO LBFGS: Val and Grad Norm: 0,00571564 (rel: 0,00153) 0,000109128\n",
      "23/03/25 03:24:48 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:48 INFO LBFGS: Val and Grad Norm: 0,00571512 (rel: 9,21e-05) 2,62013e-05\n",
      "23/03/25 03:24:48 INFO LBFGS: Converged because max iterations reached\n",
      "23/03/25 03:24:51 INFO StrongWolfeLineSearch: Line search t: 6.182519687656683 fval: 0.009270064253654967 rhs: 0.012257466161538352 cdd: -4.7758084987172043E-5\n",
      "23/03/25 03:24:51 INFO LBFGS: Step Size: 6,183\n",
      "23/03/25 03:24:51 INFO LBFGS: Val and Grad Norm: 0,00927006 (rel: 0,244) 0,00252896\n",
      "23/03/25 03:24:51 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:51 INFO LBFGS: Val and Grad Norm: 0,00924761 (rel: 0,00242) 0,00111279\n",
      "23/03/25 03:24:51 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:51 INFO LBFGS: Val and Grad Norm: 0,00924400 (rel: 0,000390) 0,000270838\n",
      "23/03/25 03:24:51 INFO LBFGS: Step Size: 3,375\n",
      "23/03/25 03:24:51 INFO LBFGS: Val and Grad Norm: 0,00924275 (rel: 0,000136) 0,000257864\n",
      "23/03/25 03:24:51 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:51 INFO LBFGS: Val and Grad Norm: 0,00923180 (rel: 0,00118) 0,000610585\n",
      "23/03/25 03:24:51 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:51 INFO LBFGS: Val and Grad Norm: 0,00922452 (rel: 0,000789) 0,000286871\n",
      "23/03/25 03:24:51 INFO StrongWolfeLineSearch: Line search t: 0.42502334915887985 fval: 0.00922422795605828 rhs: 0.009224516673657167 cdd: -1.6008582335410158E-11\n",
      "23/03/25 03:24:51 INFO LBFGS: Step Size: 0,4250\n",
      "23/03/25 03:24:51 INFO LBFGS: Val and Grad Norm: 0,00922423 (rel: 3,13e-05) 0,000200115\n",
      "23/03/25 03:24:51 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:51 INFO LBFGS: Val and Grad Norm: 0,00922402 (rel: 2,28e-05) 1,30340e-05\n",
      "23/03/25 03:24:51 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:51 INFO LBFGS: Val and Grad Norm: 0,00922402 (rel: 1,05e-07) 2,08880e-06\n",
      "23/03/25 03:24:51 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:51 INFO LBFGS: Val and Grad Norm: 0,00922402 (rel: 3,39e-09) 2,02056e-07\n",
      "23/03/25 03:24:51 INFO LBFGS: Converged because max iterations reached\n",
      "23/03/25 03:24:53 INFO StrongWolfeLineSearch: Line search t: 3.5747404889699705 fval: 0.014492360264427899 rhs: 0.012257670232766473 cdd: 0.0020496905467627456\n",
      "23/03/25 03:24:53 INFO StrongWolfeLineSearch: Line search t: 1.0007011162315322 fval: 0.011867457854110811 rhs: 0.012257871663691411 cdd: 2.3887634908894695E-6\n",
      "23/03/25 03:24:53 INFO LBFGS: Step Size: 1,001\n",
      "23/03/25 03:24:53 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 0,0319) 8,54653e-05\n",
      "23/03/25 03:24:53 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:53 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 3,07e-07) 6,19126e-07\n",
      "23/03/25 03:24:53 INFO LBFGS: Step Size: 3,375\n",
      "23/03/25 03:24:53 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 1,03e-10) 6,53799e-07\n",
      "23/03/25 03:24:53 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:53 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 1,37e-09) 3,20363e-06\n",
      "23/03/25 03:24:53 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:53 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 2,03e-09) 5,46560e-06\n",
      "23/03/25 03:24:53 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:53 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 3,20e-09) 6,30712e-06\n",
      "23/03/25 03:24:53 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:53 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 1,69e-09) 5,02178e-06\n",
      "23/03/25 03:24:53 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:53 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 7,33e-10) 2,10149e-06\n",
      "23/03/25 03:24:53 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:53 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 3,25e-10) 4,26619e-07\n",
      "23/03/25 03:24:53 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:53 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 1,14e-11) 6,64055e-08\n",
      "23/03/25 03:24:53 INFO LBFGS: Converged because max iterations reached\n",
      "23/03/25 03:24:55 INFO OWLQN: Step Size: 7,882\n",
      "23/03/25 03:24:55 INFO OWLQN: Val and Grad Norm: 0,0110218 (rel: 0,101) 0,0114850\n",
      "23/03/25 03:24:55 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:24:55 INFO OWLQN: Val and Grad Norm: 0,0102950 (rel: 0,0659) 0,00849996\n",
      "23/03/25 03:24:55 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:24:55 INFO OWLQN: Val and Grad Norm: 0,00989305 (rel: 0,0390) 0,00328311\n",
      "23/03/25 03:24:55 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:24:55 INFO OWLQN: Val and Grad Norm: 0,00976565 (rel: 0,0129) 0,00189868\n",
      "23/03/25 03:24:55 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:24:55 INFO OWLQN: Val and Grad Norm: 0,00968296 (rel: 0,00847) 0,00127399\n",
      "23/03/25 03:24:55 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:24:55 INFO OWLQN: Val and Grad Norm: 0,00966151 (rel: 0,00222) 0,000868146\n",
      "23/03/25 03:24:55 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:24:55 INFO OWLQN: Val and Grad Norm: 0,00964857 (rel: 0,00134) 0,000616560\n",
      "23/03/25 03:24:55 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:24:55 INFO OWLQN: Val and Grad Norm: 0,00964043 (rel: 0,000844) 0,000705935\n",
      "23/03/25 03:24:55 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:24:55 INFO OWLQN: Val and Grad Norm: 0,00963407 (rel: 0,000660) 0,000742845\n",
      "23/03/25 03:24:55 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:24:55 INFO OWLQN: Val and Grad Norm: 0,00962940 (rel: 0,000484) 0,000486678\n",
      "23/03/25 03:24:55 INFO OWLQN: Converged because max iterations reached\n",
      "23/03/25 03:24:56 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:24:56 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:24:57 INFO OWLQN: Step Size: 34,76\n",
      "23/03/25 03:24:57 INFO OWLQN: Val and Grad Norm: 0,0118931 (rel: 0,0298) 0,00289936\n",
      "23/03/25 03:24:57 INFO OWLQN: Step Size: 0,1250\n",
      "23/03/25 03:24:57 INFO OWLQN: Val and Grad Norm: 0,0116789 (rel: 0,0180) 0,000718915\n",
      "23/03/25 03:24:57 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:24:57 INFO OWLQN: Val and Grad Norm: 0,0116720 (rel: 0,000598) 0,000545820\n",
      "23/03/25 03:24:57 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:24:57 INFO OWLQN: Val and Grad Norm: 0,0116665 (rel: 0,000466) 0,000344270\n",
      "23/03/25 03:24:57 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:24:57 INFO OWLQN: Val and Grad Norm: 0,0116587 (rel: 0,000672) 0,000347080\n",
      "23/03/25 03:24:57 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:24:57 INFO OWLQN: Val and Grad Norm: 0,0116507 (rel: 0,000687) 0,000485476\n",
      "23/03/25 03:24:57 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:24:57 INFO OWLQN: Val and Grad Norm: 0,0116481 (rel: 0,000222) 0,000155159\n",
      "23/03/25 03:24:57 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:24:57 INFO OWLQN: Val and Grad Norm: 0,0116479 (rel: 1,90e-05) 0,000124931\n",
      "23/03/25 03:24:57 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:24:57 INFO OWLQN: Val and Grad Norm: 0,0116476 (rel: 2,17e-05) 0,000114504\n",
      "23/03/25 03:24:57 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:24:57 INFO OWLQN: Val and Grad Norm: 0,0116449 (rel: 0,000229) 0,000171209\n",
      "23/03/25 03:24:57 INFO OWLQN: Converged because max iterations reached\n",
      "23/03/25 03:24:58 INFO OWLQN: Converged because gradient converged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 03:24:58 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:24:59 INFO LBFGS: Step Size: 35,75\n",
      "23/03/25 03:24:59 INFO LBFGS: Val and Grad Norm: 0,0111986 (rel: 0,0864) 0,0139599\n",
      "23/03/25 03:24:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:59 INFO LBFGS: Val and Grad Norm: 0,00739919 (rel: 0,339) 0,00852427\n",
      "23/03/25 03:24:59 INFO StrongWolfeLineSearch: Line search t: 0.5462093482239323 fval: 0.006034047851508112 rhs: 0.007398941802148653 cdd: -3.8103740369910044E-5\n",
      "23/03/25 03:24:59 INFO LBFGS: Step Size: 0,5462\n",
      "23/03/25 03:24:59 INFO LBFGS: Val and Grad Norm: 0,00603405 (rel: 0,184) 0,00171503\n",
      "23/03/25 03:24:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:59 INFO LBFGS: Val and Grad Norm: 0,00595802 (rel: 0,0126) 0,00107296\n",
      "23/03/25 03:24:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:59 INFO LBFGS: Val and Grad Norm: 0,00588022 (rel: 0,0131) 0,000744475\n",
      "23/03/25 03:24:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:59 INFO LBFGS: Val and Grad Norm: 0,00583021 (rel: 0,00851) 0,000821299\n",
      "23/03/25 03:24:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:59 INFO LBFGS: Val and Grad Norm: 0,00573357 (rel: 0,0166) 0,000606525\n",
      "23/03/25 03:24:59 INFO StrongWolfeLineSearch: Line search t: 0.2161729614068808 fval: 0.005724419239254127 rhs: 0.005733571829132323 cdd: 9.17516334028976E-6\n",
      "23/03/25 03:24:59 INFO LBFGS: Step Size: 0,2162\n",
      "23/03/25 03:24:59 INFO LBFGS: Val and Grad Norm: 0,00572442 (rel: 0,00160) 0,000421979\n",
      "23/03/25 03:24:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:59 INFO LBFGS: Val and Grad Norm: 0,00571564 (rel: 0,00153) 0,000109128\n",
      "23/03/25 03:24:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:59 INFO LBFGS: Val and Grad Norm: 0,00571512 (rel: 9,21e-05) 2,62013e-05\n",
      "23/03/25 03:24:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:59 INFO LBFGS: Val and Grad Norm: 0,00571511 (rel: 1,32e-06) 1,08727e-05\n",
      "23/03/25 03:24:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:59 INFO LBFGS: Val and Grad Norm: 0,00571511 (rel: 2,96e-07) 9,64029e-07\n",
      "23/03/25 03:24:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:59 INFO LBFGS: Val and Grad Norm: 0,00571511 (rel: 7,73e-09) 4,93383e-07\n",
      "23/03/25 03:24:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:59 INFO LBFGS: Val and Grad Norm: 0,00571511 (rel: 9,42e-10) 2,50672e-07\n",
      "23/03/25 03:24:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:24:59 INFO LBFGS: Val and Grad Norm: 0,00571511 (rel: 3,64e-10) 2,32998e-08\n",
      "23/03/25 03:25:00 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:00 INFO LBFGS: Val and Grad Norm: 0,00571511 (rel: 3,19e-12) 2,22387e-09\n",
      "23/03/25 03:25:00 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:25:00 INFO StrongWolfeLineSearch: Line search t: 6.182519687656679 fval: 0.009270064253654967 rhs: 0.012257466161538352 cdd: -4.775808498717269E-5\n",
      "23/03/25 03:25:00 INFO LBFGS: Step Size: 6,183\n",
      "23/03/25 03:25:00 INFO LBFGS: Val and Grad Norm: 0,00927006 (rel: 0,244) 0,00252896\n",
      "23/03/25 03:25:00 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:00 INFO LBFGS: Val and Grad Norm: 0,00924761 (rel: 0,00242) 0,00111279\n",
      "23/03/25 03:25:00 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:00 INFO LBFGS: Val and Grad Norm: 0,00924400 (rel: 0,000390) 0,000270838\n",
      "23/03/25 03:25:01 INFO LBFGS: Step Size: 3,375\n",
      "23/03/25 03:25:01 INFO LBFGS: Val and Grad Norm: 0,00924275 (rel: 0,000136) 0,000257864\n",
      "23/03/25 03:25:01 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:01 INFO LBFGS: Val and Grad Norm: 0,00923180 (rel: 0,00118) 0,000610585\n",
      "23/03/25 03:25:01 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:01 INFO LBFGS: Val and Grad Norm: 0,00922452 (rel: 0,000789) 0,000286871\n",
      "23/03/25 03:25:01 INFO StrongWolfeLineSearch: Line search t: 0.425023349156307 fval: 0.009224227956058281 rhs: 0.009224516673657162 cdd: -1.6008590529077494E-11\n",
      "23/03/25 03:25:01 INFO LBFGS: Step Size: 0,4250\n",
      "23/03/25 03:25:01 INFO LBFGS: Val and Grad Norm: 0,00922423 (rel: 3,13e-05) 0,000200115\n",
      "23/03/25 03:25:01 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:01 INFO LBFGS: Val and Grad Norm: 0,00922402 (rel: 2,28e-05) 1,30340e-05\n",
      "23/03/25 03:25:01 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:01 INFO LBFGS: Val and Grad Norm: 0,00922402 (rel: 1,05e-07) 2,08880e-06\n",
      "23/03/25 03:25:01 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:01 INFO LBFGS: Val and Grad Norm: 0,00922402 (rel: 3,39e-09) 2,02056e-07\n",
      "23/03/25 03:25:01 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:01 INFO LBFGS: Val and Grad Norm: 0,00922402 (rel: 1,93e-11) 5,15677e-08\n",
      "23/03/25 03:25:01 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:01 INFO LBFGS: Val and Grad Norm: 0,00922402 (rel: 1,37e-12) 4,01603e-10\n",
      "23/03/25 03:25:01 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:25:02 INFO StrongWolfeLineSearch: Line search t: 3.5747404889699697 fval: 0.014492360264427897 rhs: 0.012257670232766471 cdd: 0.0020496905467627443\n",
      "23/03/25 03:25:02 INFO StrongWolfeLineSearch: Line search t: 1.0007011162315314 fval: 0.011867457854110813 rhs: 0.01225787166369141 cdd: 2.388763490888799E-6\n",
      "23/03/25 03:25:02 INFO LBFGS: Step Size: 1,001\n",
      "23/03/25 03:25:02 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 0,0319) 8,54653e-05\n",
      "23/03/25 03:25:02 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:02 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 3,07e-07) 6,19126e-07\n",
      "23/03/25 03:25:02 INFO LBFGS: Step Size: 3,375\n",
      "23/03/25 03:25:02 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 1,03e-10) 6,53799e-07\n",
      "23/03/25 03:25:02 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:02 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 1,37e-09) 3,20363e-06\n",
      "23/03/25 03:25:02 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:02 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 2,03e-09) 5,46560e-06\n",
      "23/03/25 03:25:02 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:02 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 3,20e-09) 6,30712e-06\n",
      "23/03/25 03:25:02 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:02 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 1,69e-09) 5,02178e-06\n",
      "23/03/25 03:25:02 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:02 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 7,33e-10) 2,10149e-06\n",
      "23/03/25 03:25:02 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:02 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 3,25e-10) 4,26619e-07\n",
      "23/03/25 03:25:02 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:02 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 1,14e-11) 6,64055e-08\n",
      "23/03/25 03:25:03 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:03 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 1,95e-13) 3,06755e-09\n",
      "23/03/25 03:25:03 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:25:03 INFO OWLQN: Step Size: 7,882\n",
      "23/03/25 03:25:03 INFO OWLQN: Val and Grad Norm: 0,0110218 (rel: 0,101) 0,0114850\n",
      "23/03/25 03:25:03 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:25:03 INFO OWLQN: Val and Grad Norm: 0,0102950 (rel: 0,0659) 0,00849996\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00989305 (rel: 0,0390) 0,00328311\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00976565 (rel: 0,0129) 0,00189868\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00968296 (rel: 0,00847) 0,00127399\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00966151 (rel: 0,00222) 0,000868146\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00964857 (rel: 0,00134) 0,000616560\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00964043 (rel: 0,000844) 0,000705935\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00963407 (rel: 0,000660) 0,000742845\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00962940 (rel: 0,000484) 0,000486678\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00962401 (rel: 0,000559) 0,000389726\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00960414 (rel: 0,00206) 0,000359340\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00959853 (rel: 0,000585) 0,000309984\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 0,5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00959769 (rel: 8,78e-05) 2,33623e-05\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00959761 (rel: 7,58e-06) 1,95462e-05\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00959761 (rel: 5,74e-07) 1,21908e-05\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 3,89e-07) 7,02275e-06\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 3,10e-07) 2,63498e-06\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 5,25e-09) 4,78164e-06\n",
      "23/03/25 03:25:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:04 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 2,17e-08) 2,22533e-06\n",
      "23/03/25 03:25:04 INFO OWLQN: Converged because max iterations reached\n",
      "23/03/25 03:25:05 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:06 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:06 INFO OWLQN: Step Size: 34,76\n",
      "23/03/25 03:25:06 INFO OWLQN: Val and Grad Norm: 0,0118931 (rel: 0,0298) 0,00289936\n",
      "23/03/25 03:25:06 INFO OWLQN: Step Size: 0,1250\n",
      "23/03/25 03:25:06 INFO OWLQN: Val and Grad Norm: 0,0116789 (rel: 0,0180) 0,000718915\n",
      "23/03/25 03:25:06 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:06 INFO OWLQN: Val and Grad Norm: 0,0116720 (rel: 0,000598) 0,000545820\n",
      "23/03/25 03:25:06 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:06 INFO OWLQN: Val and Grad Norm: 0,0116665 (rel: 0,000466) 0,000344270\n",
      "23/03/25 03:25:06 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:06 INFO OWLQN: Val and Grad Norm: 0,0116587 (rel: 0,000672) 0,000347080\n",
      "23/03/25 03:25:06 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:06 INFO OWLQN: Val and Grad Norm: 0,0116507 (rel: 0,000687) 0,000485476\n",
      "23/03/25 03:25:06 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:06 INFO OWLQN: Val and Grad Norm: 0,0116481 (rel: 0,000222) 0,000155159\n",
      "23/03/25 03:25:06 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:06 INFO OWLQN: Val and Grad Norm: 0,0116479 (rel: 1,90e-05) 0,000124931\n",
      "23/03/25 03:25:07 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:07 INFO OWLQN: Val and Grad Norm: 0,0116476 (rel: 2,17e-05) 0,000114504\n",
      "23/03/25 03:25:07 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:07 INFO OWLQN: Val and Grad Norm: 0,0116449 (rel: 0,000229) 0,000171209\n",
      "23/03/25 03:25:07 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:07 INFO OWLQN: Val and Grad Norm: 0,0116443 (rel: 5,34e-05) 0,000213395\n",
      "23/03/25 03:25:07 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:07 INFO OWLQN: Val and Grad Norm: 0,0116440 (rel: 2,54e-05) 0,000162986\n",
      "23/03/25 03:25:07 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:07 INFO OWLQN: Val and Grad Norm: 0,0116438 (rel: 1,56e-05) 9,77016e-05\n",
      "23/03/25 03:25:07 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:07 INFO OWLQN: Val and Grad Norm: 0,0116438 (rel: 6,25e-06) 5,42979e-05\n",
      "23/03/25 03:25:07 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:07 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 1,80e-06) 3,09939e-05\n",
      "23/03/25 03:25:07 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:07 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 9,56e-07) 8,04273e-07\n",
      "23/03/25 03:25:07 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:07 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 2,47e-09) 8,20429e-07\n",
      "23/03/25 03:25:07 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:07 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 1,02e-09) 1,48985e-06\n",
      "23/03/25 03:25:07 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:07 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 5,93e-10) 1,69865e-06\n",
      "23/03/25 03:25:07 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:07 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 2,50e-09) 8,99506e-07\n",
      "23/03/25 03:25:07 INFO OWLQN: Converged because max iterations reached\n",
      "23/03/25 03:25:08 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:08 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:08 INFO LBFGS: Step Size: 35,75\n",
      "23/03/25 03:25:08 INFO LBFGS: Val and Grad Norm: 0,0111986 (rel: 0,0864) 0,0139599\n",
      "23/03/25 03:25:09 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:09 INFO LBFGS: Val and Grad Norm: 0,00739919 (rel: 0,339) 0,00852427\n",
      "23/03/25 03:25:09 INFO StrongWolfeLineSearch: Line search t: 0.5462093482239323 fval: 0.006034047851508112 rhs: 0.007398941802148653 cdd: -3.810374036990963E-5\n",
      "23/03/25 03:25:09 INFO LBFGS: Step Size: 0,5462\n",
      "23/03/25 03:25:09 INFO LBFGS: Val and Grad Norm: 0,00603405 (rel: 0,184) 0,00171503\n",
      "23/03/25 03:25:09 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:09 INFO LBFGS: Val and Grad Norm: 0,00595802 (rel: 0,0126) 0,00107296\n",
      "23/03/25 03:25:09 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:09 INFO LBFGS: Val and Grad Norm: 0,00588022 (rel: 0,0131) 0,000744475\n",
      "23/03/25 03:25:09 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:09 INFO LBFGS: Val and Grad Norm: 0,00583021 (rel: 0,00851) 0,000821299\n",
      "23/03/25 03:25:09 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:09 INFO LBFGS: Val and Grad Norm: 0,00573357 (rel: 0,0166) 0,000606525\n",
      "23/03/25 03:25:09 INFO StrongWolfeLineSearch: Line search t: 0.21617296140687692 fval: 0.005724419239254127 rhs: 0.0057335718291323225 cdd: 9.175163340288482E-6\n",
      "23/03/25 03:25:09 INFO LBFGS: Step Size: 0,2162\n",
      "23/03/25 03:25:09 INFO LBFGS: Val and Grad Norm: 0,00572442 (rel: 0,00160) 0,000421979\n",
      "23/03/25 03:25:09 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:09 INFO LBFGS: Val and Grad Norm: 0,00571564 (rel: 0,00153) 0,000109128\n",
      "23/03/25 03:25:09 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:09 INFO LBFGS: Val and Grad Norm: 0,00571512 (rel: 9,21e-05) 2,62013e-05\n",
      "23/03/25 03:25:09 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:09 INFO LBFGS: Val and Grad Norm: 0,00571511 (rel: 1,32e-06) 1,08727e-05\n",
      "23/03/25 03:25:09 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:09 INFO LBFGS: Val and Grad Norm: 0,00571511 (rel: 2,96e-07) 9,64029e-07\n",
      "23/03/25 03:25:09 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:09 INFO LBFGS: Val and Grad Norm: 0,00571511 (rel: 7,73e-09) 4,93383e-07\n",
      "23/03/25 03:25:09 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:09 INFO LBFGS: Val and Grad Norm: 0,00571511 (rel: 9,42e-10) 2,50672e-07\n",
      "23/03/25 03:25:09 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:09 INFO LBFGS: Val and Grad Norm: 0,00571511 (rel: 3,64e-10) 2,32998e-08\n",
      "23/03/25 03:25:09 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:09 INFO LBFGS: Val and Grad Norm: 0,00571511 (rel: 3,19e-12) 2,22387e-09\n",
      "23/03/25 03:25:09 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:25:10 INFO StrongWolfeLineSearch: Line search t: 6.182519687656676 fval: 0.009270064253654968 rhs: 0.01225746616153835 cdd: -4.77580849871734E-5\n",
      "23/03/25 03:25:10 INFO LBFGS: Step Size: 6,183\n",
      "23/03/25 03:25:10 INFO LBFGS: Val and Grad Norm: 0,00927006 (rel: 0,244) 0,00252896\n",
      "23/03/25 03:25:10 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:10 INFO LBFGS: Val and Grad Norm: 0,00924761 (rel: 0,00242) 0,00111279\n",
      "23/03/25 03:25:10 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:10 INFO LBFGS: Val and Grad Norm: 0,00924400 (rel: 0,000390) 0,000270838\n",
      "23/03/25 03:25:10 INFO LBFGS: Step Size: 3,375\n",
      "23/03/25 03:25:10 INFO LBFGS: Val and Grad Norm: 0,00924275 (rel: 0,000136) 0,000257864\n",
      "23/03/25 03:25:10 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:10 INFO LBFGS: Val and Grad Norm: 0,00923180 (rel: 0,00118) 0,000610585\n",
      "23/03/25 03:25:10 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:10 INFO LBFGS: Val and Grad Norm: 0,00922452 (rel: 0,000789) 0,000286871\n",
      "23/03/25 03:25:10 INFO StrongWolfeLineSearch: Line search t: 0.42502334915550233 fval: 0.009224227956058277 rhs: 0.009224516673657158 cdd: -1.6008592608861017E-11\n",
      "23/03/25 03:25:10 INFO LBFGS: Step Size: 0,4250\n",
      "23/03/25 03:25:10 INFO LBFGS: Val and Grad Norm: 0,00922423 (rel: 3,13e-05) 0,000200115\n",
      "23/03/25 03:25:10 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:10 INFO LBFGS: Val and Grad Norm: 0,00922402 (rel: 2,28e-05) 1,30340e-05\n",
      "23/03/25 03:25:10 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:10 INFO LBFGS: Val and Grad Norm: 0,00922402 (rel: 1,05e-07) 2,08880e-06\n",
      "23/03/25 03:25:10 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:10 INFO LBFGS: Val and Grad Norm: 0,00922402 (rel: 3,39e-09) 2,02056e-07\n",
      "23/03/25 03:25:10 INFO LBFGS: Step Size: 1,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 03:25:10 INFO LBFGS: Val and Grad Norm: 0,00922402 (rel: 1,93e-11) 5,15677e-08\n",
      "23/03/25 03:25:11 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:11 INFO LBFGS: Val and Grad Norm: 0,00922402 (rel: 1,37e-12) 4,01603e-10\n",
      "23/03/25 03:25:11 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:25:11 INFO StrongWolfeLineSearch: Line search t: 3.5747404889699705 fval: 0.014492360264427899 rhs: 0.012257670232766471 cdd: 0.002049690546762745\n",
      "23/03/25 03:25:11 INFO StrongWolfeLineSearch: Line search t: 1.000701116231531 fval: 0.01186745785411081 rhs: 0.01225787166369141 cdd: 2.388763490888436E-6\n",
      "23/03/25 03:25:11 INFO LBFGS: Step Size: 1,001\n",
      "23/03/25 03:25:11 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 0,0319) 8,54653e-05\n",
      "23/03/25 03:25:11 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:11 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 3,07e-07) 6,19126e-07\n",
      "23/03/25 03:25:12 INFO LBFGS: Step Size: 3,375\n",
      "23/03/25 03:25:12 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 1,03e-10) 6,53799e-07\n",
      "23/03/25 03:25:12 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:12 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 1,37e-09) 3,20363e-06\n",
      "23/03/25 03:25:12 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:12 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 2,03e-09) 5,46560e-06\n",
      "23/03/25 03:25:12 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:12 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 3,20e-09) 6,30712e-06\n",
      "23/03/25 03:25:12 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:12 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 1,69e-09) 5,02178e-06\n",
      "23/03/25 03:25:12 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:12 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 7,33e-10) 2,10149e-06\n",
      "23/03/25 03:25:12 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:12 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 3,25e-10) 4,26619e-07\n",
      "23/03/25 03:25:12 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:12 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 1,14e-11) 6,64055e-08\n",
      "23/03/25 03:25:12 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:12 INFO LBFGS: Val and Grad Norm: 0,0118675 (rel: 1,95e-13) 3,06755e-09\n",
      "23/03/25 03:25:12 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:25:13 INFO OWLQN: Step Size: 7,882\n",
      "23/03/25 03:25:13 INFO OWLQN: Val and Grad Norm: 0,0110218 (rel: 0,101) 0,0114850\n",
      "23/03/25 03:25:13 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:25:13 INFO OWLQN: Val and Grad Norm: 0,0102950 (rel: 0,0659) 0,00849996\n",
      "23/03/25 03:25:13 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:13 INFO OWLQN: Val and Grad Norm: 0,00989305 (rel: 0,0390) 0,00328311\n",
      "23/03/25 03:25:13 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:13 INFO OWLQN: Val and Grad Norm: 0,00976565 (rel: 0,0129) 0,00189868\n",
      "23/03/25 03:25:13 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:13 INFO OWLQN: Val and Grad Norm: 0,00968296 (rel: 0,00847) 0,00127399\n",
      "23/03/25 03:25:13 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:13 INFO OWLQN: Val and Grad Norm: 0,00966151 (rel: 0,00222) 0,000868146\n",
      "23/03/25 03:25:13 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:13 INFO OWLQN: Val and Grad Norm: 0,00964857 (rel: 0,00134) 0,000616560\n",
      "23/03/25 03:25:13 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:13 INFO OWLQN: Val and Grad Norm: 0,00964043 (rel: 0,000844) 0,000705935\n",
      "23/03/25 03:25:13 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:13 INFO OWLQN: Val and Grad Norm: 0,00963407 (rel: 0,000660) 0,000742845\n",
      "23/03/25 03:25:13 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:13 INFO OWLQN: Val and Grad Norm: 0,00962940 (rel: 0,000484) 0,000486678\n",
      "23/03/25 03:25:13 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:13 INFO OWLQN: Val and Grad Norm: 0,00962401 (rel: 0,000559) 0,000389726\n",
      "23/03/25 03:25:13 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:13 INFO OWLQN: Val and Grad Norm: 0,00960414 (rel: 0,00206) 0,000359340\n",
      "23/03/25 03:25:13 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:13 INFO OWLQN: Val and Grad Norm: 0,00959853 (rel: 0,000585) 0,000309984\n",
      "23/03/25 03:25:13 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:13 INFO OWLQN: Val and Grad Norm: 0,00959769 (rel: 8,78e-05) 2,33623e-05\n",
      "23/03/25 03:25:13 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:13 INFO OWLQN: Val and Grad Norm: 0,00959761 (rel: 7,58e-06) 1,95462e-05\n",
      "23/03/25 03:25:13 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:25:13 INFO OWLQN: Val and Grad Norm: 0,00959761 (rel: 5,74e-07) 1,21908e-05\n",
      "23/03/25 03:25:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:14 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 3,89e-07) 7,02275e-06\n",
      "23/03/25 03:25:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:14 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 3,10e-07) 2,63498e-06\n",
      "23/03/25 03:25:14 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:14 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 5,25e-09) 4,78164e-06\n",
      "23/03/25 03:25:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:14 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 2,17e-08) 2,22533e-06\n",
      "23/03/25 03:25:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:14 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 3,33e-09) 1,09056e-06\n",
      "23/03/25 03:25:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:14 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 1,27e-09) 5,77038e-07\n",
      "23/03/25 03:25:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:14 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 3,68e-10) 3,14677e-07\n",
      "23/03/25 03:25:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:14 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 3,06e-10) 2,42348e-07\n",
      "23/03/25 03:25:14 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:14 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 2,04e-10) 3,41228e-07\n",
      "23/03/25 03:25:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:14 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 9,63e-11) 2,63958e-07\n",
      "23/03/25 03:25:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:14 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 5,20e-11) 1,33644e-07\n",
      "23/03/25 03:25:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:14 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 1,25e-11) 7,08862e-08\n",
      "23/03/25 03:25:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:14 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 3,76e-12) 3,10739e-08\n",
      "23/03/25 03:25:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:14 INFO OWLQN: Val and Grad Norm: 0,00959760 (rel: 7,10e-13) 1,59196e-08\n",
      "23/03/25 03:25:14 INFO OWLQN: Converged because max iterations reached\n",
      "23/03/25 03:25:15 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:15 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:16 INFO OWLQN: Step Size: 34,76\n",
      "23/03/25 03:25:16 INFO OWLQN: Val and Grad Norm: 0,0118931 (rel: 0,0298) 0,00289936\n",
      "23/03/25 03:25:16 INFO OWLQN: Step Size: 0,1250\n",
      "23/03/25 03:25:16 INFO OWLQN: Val and Grad Norm: 0,0116789 (rel: 0,0180) 0,000718915\n",
      "23/03/25 03:25:16 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:16 INFO OWLQN: Val and Grad Norm: 0,0116720 (rel: 0,000598) 0,000545820\n",
      "23/03/25 03:25:16 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:16 INFO OWLQN: Val and Grad Norm: 0,0116665 (rel: 0,000466) 0,000344270\n",
      "23/03/25 03:25:16 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:16 INFO OWLQN: Val and Grad Norm: 0,0116587 (rel: 0,000672) 0,000347080\n",
      "23/03/25 03:25:16 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:16 INFO OWLQN: Val and Grad Norm: 0,0116507 (rel: 0,000687) 0,000485476\n",
      "23/03/25 03:25:16 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:16 INFO OWLQN: Val and Grad Norm: 0,0116481 (rel: 0,000222) 0,000155159\n",
      "23/03/25 03:25:16 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:16 INFO OWLQN: Val and Grad Norm: 0,0116479 (rel: 1,90e-05) 0,000124931\n",
      "23/03/25 03:25:16 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:16 INFO OWLQN: Val and Grad Norm: 0,0116476 (rel: 2,17e-05) 0,000114504\n",
      "23/03/25 03:25:16 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:16 INFO OWLQN: Val and Grad Norm: 0,0116449 (rel: 0,000229) 0,000171209\n",
      "23/03/25 03:25:16 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:16 INFO OWLQN: Val and Grad Norm: 0,0116443 (rel: 5,34e-05) 0,000213395\n",
      "23/03/25 03:25:16 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:16 INFO OWLQN: Val and Grad Norm: 0,0116440 (rel: 2,54e-05) 0,000162986\n",
      "23/03/25 03:25:16 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:16 INFO OWLQN: Val and Grad Norm: 0,0116438 (rel: 1,56e-05) 9,77016e-05\n",
      "23/03/25 03:25:16 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:16 INFO OWLQN: Val and Grad Norm: 0,0116438 (rel: 6,25e-06) 5,42979e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 03:25:16 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:16 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 1,80e-06) 3,09939e-05\n",
      "23/03/25 03:25:16 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:16 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 9,56e-07) 8,04273e-07\n",
      "23/03/25 03:25:17 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:17 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 2,47e-09) 8,20429e-07\n",
      "23/03/25 03:25:17 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:17 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 1,02e-09) 1,48985e-06\n",
      "23/03/25 03:25:17 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:17 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 5,93e-10) 1,69865e-06\n",
      "23/03/25 03:25:17 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:17 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 2,50e-09) 8,99506e-07\n",
      "23/03/25 03:25:17 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:17 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 6,49e-10) 6,99365e-07\n",
      "23/03/25 03:25:17 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:17 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 3,21e-10) 4,11990e-07\n",
      "23/03/25 03:25:17 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:17 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 1,37e-10) 2,27422e-07\n",
      "23/03/25 03:25:17 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:17 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 4,49e-11) 1,17458e-07\n",
      "23/03/25 03:25:17 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:17 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 1,35e-11) 7,12164e-08\n",
      "23/03/25 03:25:17 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:17 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 5,52e-12) 3,13723e-08\n",
      "23/03/25 03:25:17 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:17 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 9,98e-13) 2,39289e-08\n",
      "23/03/25 03:25:17 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:17 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 7,13e-13) 1,33876e-08\n",
      "23/03/25 03:25:17 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:17 INFO OWLQN: Val and Grad Norm: 0,0116437 (rel: 1,60e-13) 8,93963e-09\n",
      "23/03/25 03:25:17 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:18 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:18 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:19 INFO LBFGS: Step Size: 33,04\n",
      "23/03/25 03:25:19 INFO LBFGS: Val and Grad Norm: 0,0124009 (rel: 0,0416) 0,0146681\n",
      "23/03/25 03:25:19 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:19 INFO LBFGS: Val and Grad Norm: 0,00840514 (rel: 0,322) 0,00973508\n",
      "23/03/25 03:25:19 INFO StrongWolfeLineSearch: Line search t: 0.44398297929103925 fval: 0.006551533655429769 rhs: 0.008404860644154325 cdd: -0.0014489826697765206\n",
      "23/03/25 03:25:19 INFO LBFGS: Step Size: 0,4440\n",
      "23/03/25 03:25:19 INFO LBFGS: Val and Grad Norm: 0,00655153 (rel: 0,221) 0,00256710\n",
      "23/03/25 03:25:19 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:19 INFO LBFGS: Val and Grad Norm: 0,00645028 (rel: 0,0155) 0,00322521\n",
      "23/03/25 03:25:19 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:19 INFO LBFGS: Val and Grad Norm: 0,00638050 (rel: 0,0108) 0,000857616\n",
      "23/03/25 03:25:19 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:19 INFO LBFGS: Val and Grad Norm: 0,00635989 (rel: 0,00323) 0,000782793\n",
      "23/03/25 03:25:19 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:19 INFO LBFGS: Val and Grad Norm: 0,00630519 (rel: 0,00860) 0,000886009\n",
      "23/03/25 03:25:19 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:19 INFO LBFGS: Val and Grad Norm: 0,00619913 (rel: 0,0168) 0,000862107\n",
      "23/03/25 03:25:19 INFO StrongWolfeLineSearch: Line search t: 0.48493449589455706 fval: 0.006174017613898908 rhs: 0.00619911990221756 cdd: 4.380525512916449E-9\n",
      "23/03/25 03:25:19 INFO LBFGS: Step Size: 0,4849\n",
      "23/03/25 03:25:19 INFO LBFGS: Val and Grad Norm: 0,00617402 (rel: 0,00405) 0,000727022\n",
      "23/03/25 03:25:19 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:19 INFO LBFGS: Val and Grad Norm: 0,00615038 (rel: 0,00383) 0,000157010\n",
      "23/03/25 03:25:19 INFO LBFGS: Converged because max iterations reached\n",
      "23/03/25 03:25:21 INFO StrongWolfeLineSearch: Line search t: 5.842202960675703 fval: 0.009618214091292477 rhs: 0.012938721118997396 cdd: -3.713617878698192E-5\n",
      "23/03/25 03:25:21 INFO LBFGS: Step Size: 5,842\n",
      "23/03/25 03:25:21 INFO LBFGS: Val and Grad Norm: 0,00961821 (rel: 0,257) 0,00250205\n",
      "23/03/25 03:25:21 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:21 INFO LBFGS: Val and Grad Norm: 0,00959418 (rel: 0,00250) 0,00108791\n",
      "23/03/25 03:25:21 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:21 INFO LBFGS: Val and Grad Norm: 0,00959008 (rel: 0,000427) 0,000498566\n",
      "23/03/25 03:25:21 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:21 INFO LBFGS: Val and Grad Norm: 0,00958922 (rel: 8,92e-05) 0,000323923\n",
      "23/03/25 03:25:21 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:21 INFO LBFGS: Val and Grad Norm: 0,00958747 (rel: 0,000182) 0,000500035\n",
      "23/03/25 03:25:21 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:21 INFO LBFGS: Val and Grad Norm: 0,00958398 (rel: 0,000364) 0,000954644\n",
      "23/03/25 03:25:21 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:21 INFO LBFGS: Val and Grad Norm: 0,00957695 (rel: 0,000733) 0,00143349\n",
      "23/03/25 03:25:21 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:21 INFO LBFGS: Val and Grad Norm: 0,00956768 (rel: 0,000969) 0,00144266\n",
      "23/03/25 03:25:21 INFO StrongWolfeLineSearch: Line search t: 0.13594763760192774 fval: 0.009566549436697304 rhs: 0.009567675873940727 cdd: -9.400020378773584E-9\n",
      "23/03/25 03:25:21 INFO LBFGS: Step Size: 0,1359\n",
      "23/03/25 03:25:21 INFO LBFGS: Val and Grad Norm: 0,00956655 (rel: 0,000118) 0,00124901\n",
      "23/03/25 03:25:21 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:21 INFO LBFGS: Val and Grad Norm: 0,00956203 (rel: 0,000472) 0,000582060\n",
      "23/03/25 03:25:21 INFO LBFGS: Converged because max iterations reached\n",
      "23/03/25 03:25:22 INFO StrongWolfeLineSearch: Line search t: 3.304353593687594 fval: 0.014951561729301299 rhs: 0.012938953549334742 cdd: 0.002155976279615118\n",
      "23/03/25 03:25:22 INFO StrongWolfeLineSearch: Line search t: 1.000267813747079 fval: 0.012482471316135427 rhs: 0.012939164570304732 cdd: 2.9822319455134233E-6\n",
      "23/03/25 03:25:22 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:22 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 0,0353) 9,87529e-05\n",
      "23/03/25 03:25:22 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:22 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 3,89e-07) 1,10391e-06\n",
      "23/03/25 03:25:22 INFO LBFGS: Step Size: 5,063\n",
      "23/03/25 03:25:22 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 4,60e-10) 1,26574e-06\n",
      "23/03/25 03:25:22 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:22 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 5,03e-09) 6,23648e-06\n",
      "23/03/25 03:25:22 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:22 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 7,06e-09) 1,00255e-05\n",
      "23/03/25 03:25:22 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:22 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 9,10e-09) 9,86627e-06\n",
      "23/03/25 03:25:23 INFO StrongWolfeLineSearch: Line search t: 0.1 fval: 0.012482466186642477 rhs: 0.012482466192682996 cdd: 1.1117768823003422E-11\n",
      "23/03/25 03:25:23 INFO LBFGS: Step Size: 0,1000\n",
      "23/03/25 03:25:23 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 4,84e-10) 9,59993e-06\n",
      "23/03/25 03:25:23 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:23 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 4,20e-09) 4,13482e-06\n",
      "23/03/25 03:25:23 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:23 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 6,55e-10) 6,41089e-07\n",
      "23/03/25 03:25:23 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:23 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 2,87e-11) 2,15173e-08\n",
      "23/03/25 03:25:23 INFO LBFGS: Converged because max iterations reached\n",
      "23/03/25 03:25:24 INFO OWLQN: Step Size: 7,286\n",
      "23/03/25 03:25:24 INFO OWLQN: Val and Grad Norm: 0,0114277 (rel: 0,117) 0,0129577\n",
      "23/03/25 03:25:24 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:25:24 INFO OWLQN: Val and Grad Norm: 0,0106905 (rel: 0,0645) 0,00897698\n",
      "23/03/25 03:25:24 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:24 INFO OWLQN: Val and Grad Norm: 0,0103003 (rel: 0,0365) 0,00372076\n",
      "23/03/25 03:25:24 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:24 INFO OWLQN: Val and Grad Norm: 0,0101679 (rel: 0,0129) 0,00235315\n",
      "23/03/25 03:25:24 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:24 INFO OWLQN: Val and Grad Norm: 0,0100377 (rel: 0,0128) 0,00156061\n",
      "23/03/25 03:25:24 INFO OWLQN: Step Size: 1,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 03:25:24 INFO OWLQN: Val and Grad Norm: 0,0100131 (rel: 0,00245) 0,000688478\n",
      "23/03/25 03:25:24 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:24 INFO OWLQN: Val and Grad Norm: 0,00999630 (rel: 0,00168) 0,00101788\n",
      "23/03/25 03:25:24 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:24 INFO OWLQN: Val and Grad Norm: 0,00998057 (rel: 0,00157) 0,000721596\n",
      "23/03/25 03:25:24 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:24 INFO OWLQN: Val and Grad Norm: 0,00997474 (rel: 0,000584) 0,000673085\n",
      "23/03/25 03:25:24 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:24 INFO OWLQN: Val and Grad Norm: 0,00996986 (rel: 0,000489) 0,000862722\n",
      "23/03/25 03:25:24 INFO OWLQN: Converged because max iterations reached\n",
      "23/03/25 03:25:25 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:25 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:26 INFO OWLQN: Step Size: 32,13\n",
      "23/03/25 03:25:26 INFO OWLQN: Val and Grad Norm: 0,0122920 (rel: 0,0500) 0,00340841\n",
      "23/03/25 03:25:26 INFO OWLQN: Step Size: 0,1250\n",
      "23/03/25 03:25:26 INFO OWLQN: Val and Grad Norm: 0,0121422 (rel: 0,0122) 0,00135533\n",
      "23/03/25 03:25:26 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:26 INFO OWLQN: Val and Grad Norm: 0,0121148 (rel: 0,00225) 0,00161797\n",
      "23/03/25 03:25:26 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:26 INFO OWLQN: Val and Grad Norm: 0,0121054 (rel: 0,000779) 0,00259678\n",
      "23/03/25 03:25:26 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:26 INFO OWLQN: Val and Grad Norm: 0,0120621 (rel: 0,00358) 0,000648888\n",
      "23/03/25 03:25:26 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:26 INFO OWLQN: Val and Grad Norm: 0,0120552 (rel: 0,000568) 0,00116812\n",
      "23/03/25 03:25:26 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:26 INFO OWLQN: Val and Grad Norm: 0,0120507 (rel: 0,000375) 0,000859944\n",
      "23/03/25 03:25:26 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:26 INFO OWLQN: Val and Grad Norm: 0,0120477 (rel: 0,000249) 0,00129039\n",
      "23/03/25 03:25:26 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:26 INFO OWLQN: Val and Grad Norm: 0,0120341 (rel: 0,00113) 0,000233306\n",
      "23/03/25 03:25:26 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:26 INFO OWLQN: Val and Grad Norm: 0,0120300 (rel: 0,000335) 0,000271509\n",
      "23/03/25 03:25:26 INFO OWLQN: Converged because max iterations reached\n",
      "23/03/25 03:25:27 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:27 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:27 INFO LBFGS: Step Size: 33,04\n",
      "23/03/25 03:25:27 INFO LBFGS: Val and Grad Norm: 0,0124009 (rel: 0,0416) 0,0146681\n",
      "23/03/25 03:25:27 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:27 INFO LBFGS: Val and Grad Norm: 0,00840514 (rel: 0,322) 0,00973508\n",
      "23/03/25 03:25:27 INFO StrongWolfeLineSearch: Line search t: 0.4439829792910396 fval: 0.006551533655429768 rhs: 0.008404860644154324 cdd: -0.0014489826697765167\n",
      "23/03/25 03:25:27 INFO LBFGS: Step Size: 0,4440\n",
      "23/03/25 03:25:27 INFO LBFGS: Val and Grad Norm: 0,00655153 (rel: 0,221) 0,00256710\n",
      "23/03/25 03:25:28 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:28 INFO LBFGS: Val and Grad Norm: 0,00645028 (rel: 0,0155) 0,00322521\n",
      "23/03/25 03:25:28 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:28 INFO LBFGS: Val and Grad Norm: 0,00638050 (rel: 0,0108) 0,000857616\n",
      "23/03/25 03:25:28 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:28 INFO LBFGS: Val and Grad Norm: 0,00635989 (rel: 0,00323) 0,000782793\n",
      "23/03/25 03:25:28 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:28 INFO LBFGS: Val and Grad Norm: 0,00630519 (rel: 0,00860) 0,000886009\n",
      "23/03/25 03:25:28 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:28 INFO LBFGS: Val and Grad Norm: 0,00619913 (rel: 0,0168) 0,000862107\n",
      "23/03/25 03:25:28 INFO StrongWolfeLineSearch: Line search t: 0.48493449589456383 fval: 0.006174017613898907 rhs: 0.0061991199022175605 cdd: 4.38052551217106E-9\n",
      "23/03/25 03:25:28 INFO LBFGS: Step Size: 0,4849\n",
      "23/03/25 03:25:28 INFO LBFGS: Val and Grad Norm: 0,00617402 (rel: 0,00405) 0,000727022\n",
      "23/03/25 03:25:28 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:28 INFO LBFGS: Val and Grad Norm: 0,00615038 (rel: 0,00383) 0,000157010\n",
      "23/03/25 03:25:28 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:28 INFO LBFGS: Val and Grad Norm: 0,00614988 (rel: 8,09e-05) 1,81088e-05\n",
      "23/03/25 03:25:28 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:28 INFO LBFGS: Val and Grad Norm: 0,00614988 (rel: 1,19e-06) 4,76980e-06\n",
      "23/03/25 03:25:28 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:28 INFO LBFGS: Val and Grad Norm: 0,00614988 (rel: 1,07e-07) 5,94630e-07\n",
      "23/03/25 03:25:28 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:28 INFO LBFGS: Val and Grad Norm: 0,00614988 (rel: 1,17e-09) 1,83626e-07\n",
      "23/03/25 03:25:28 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:28 INFO LBFGS: Val and Grad Norm: 0,00614988 (rel: 1,05e-10) 1,72886e-08\n",
      "23/03/25 03:25:28 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:28 INFO LBFGS: Val and Grad Norm: 0,00614988 (rel: 1,50e-12) 9,46172e-09\n",
      "23/03/25 03:25:28 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:25:29 INFO StrongWolfeLineSearch: Line search t: 5.842202960675706 fval: 0.009618214091292477 rhs: 0.012938721118997397 cdd: -3.71361787869812E-5\n",
      "23/03/25 03:25:29 INFO LBFGS: Step Size: 5,842\n",
      "23/03/25 03:25:29 INFO LBFGS: Val and Grad Norm: 0,00961821 (rel: 0,257) 0,00250205\n",
      "23/03/25 03:25:29 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:29 INFO LBFGS: Val and Grad Norm: 0,00959418 (rel: 0,00250) 0,00108791\n",
      "23/03/25 03:25:29 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:29 INFO LBFGS: Val and Grad Norm: 0,00959008 (rel: 0,000427) 0,000498566\n",
      "23/03/25 03:25:29 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:29 INFO LBFGS: Val and Grad Norm: 0,00958922 (rel: 8,92e-05) 0,000323923\n",
      "23/03/25 03:25:29 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:29 INFO LBFGS: Val and Grad Norm: 0,00958747 (rel: 0,000182) 0,000500035\n",
      "23/03/25 03:25:29 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:29 INFO LBFGS: Val and Grad Norm: 0,00958398 (rel: 0,000364) 0,000954644\n",
      "23/03/25 03:25:29 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:29 INFO LBFGS: Val and Grad Norm: 0,00957695 (rel: 0,000733) 0,00143349\n",
      "23/03/25 03:25:29 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:29 INFO LBFGS: Val and Grad Norm: 0,00956768 (rel: 0,000969) 0,00144266\n",
      "23/03/25 03:25:29 INFO StrongWolfeLineSearch: Line search t: 0.13594763760194217 fval: 0.009566549436697302 rhs: 0.009567675873940728 cdd: -9.40002037579711E-9\n",
      "23/03/25 03:25:29 INFO LBFGS: Step Size: 0,1359\n",
      "23/03/25 03:25:29 INFO LBFGS: Val and Grad Norm: 0,00956655 (rel: 0,000118) 0,00124901\n",
      "23/03/25 03:25:29 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:29 INFO LBFGS: Val and Grad Norm: 0,00956203 (rel: 0,000472) 0,000582060\n",
      "23/03/25 03:25:29 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:29 INFO LBFGS: Val and Grad Norm: 0,00956127 (rel: 7,98e-05) 0,000106328\n",
      "23/03/25 03:25:29 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:29 INFO LBFGS: Val and Grad Norm: 0,00956123 (rel: 4,25e-06) 7,89190e-06\n",
      "23/03/25 03:25:29 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:29 INFO LBFGS: Val and Grad Norm: 0,00956123 (rel: 1,38e-07) 1,00869e-06\n",
      "23/03/25 03:25:29 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:29 INFO LBFGS: Val and Grad Norm: 0,00956123 (rel: 6,21e-10) 4,70925e-07\n",
      "23/03/25 03:25:29 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:29 INFO LBFGS: Val and Grad Norm: 0,00956123 (rel: 1,03e-10) 1,08349e-07\n",
      "23/03/25 03:25:29 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:29 INFO LBFGS: Val and Grad Norm: 0,00956123 (rel: 6,67e-12) 7,35820e-09\n",
      "23/03/25 03:25:29 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:25:30 INFO StrongWolfeLineSearch: Line search t: 3.304353593687594 fval: 0.014951561729301299 rhs: 0.012938953549334742 cdd: 0.002155976279615118\n",
      "23/03/25 03:25:30 INFO StrongWolfeLineSearch: Line search t: 1.000267813747079 fval: 0.012482471316135429 rhs: 0.012939164570304732 cdd: 2.982231945513412E-6\n",
      "23/03/25 03:25:30 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:30 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 0,0353) 9,87529e-05\n",
      "23/03/25 03:25:30 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:30 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 3,89e-07) 1,10391e-06\n",
      "23/03/25 03:25:30 INFO LBFGS: Step Size: 5,063\n",
      "23/03/25 03:25:30 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 4,60e-10) 1,26574e-06\n",
      "23/03/25 03:25:30 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:30 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 5,03e-09) 6,23648e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 03:25:30 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:30 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 7,06e-09) 1,00255e-05\n",
      "23/03/25 03:25:30 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:30 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 9,10e-09) 9,86627e-06\n",
      "23/03/25 03:25:31 INFO StrongWolfeLineSearch: Line search t: 0.1 fval: 0.012482466186642475 rhs: 0.012482466192682996 cdd: 1.1117769398238953E-11\n",
      "23/03/25 03:25:31 INFO LBFGS: Step Size: 0,1000\n",
      "23/03/25 03:25:31 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 4,84e-10) 9,59993e-06\n",
      "23/03/25 03:25:31 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:31 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 4,20e-09) 4,13482e-06\n",
      "23/03/25 03:25:31 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:31 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 6,55e-10) 6,41089e-07\n",
      "23/03/25 03:25:31 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:31 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 2,87e-11) 2,15173e-08\n",
      "23/03/25 03:25:31 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:31 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 3,53e-13) 3,44249e-09\n",
      "23/03/25 03:25:31 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 7,286\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,0114277 (rel: 0,117) 0,0129577\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,0106905 (rel: 0,0645) 0,00897698\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,0103003 (rel: 0,0365) 0,00372076\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,0101679 (rel: 0,0129) 0,00235315\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,0100377 (rel: 0,0128) 0,00156061\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,0100131 (rel: 0,00245) 0,000688478\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,00999630 (rel: 0,00168) 0,00101788\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,00998057 (rel: 0,00157) 0,000721596\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,00997474 (rel: 0,000584) 0,000673085\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,00996986 (rel: 0,000489) 0,000862722\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,00996563 (rel: 0,000424) 0,000489289\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,00995914 (rel: 0,000652) 0,000494459\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,00994173 (rel: 0,00175) 0,000251099\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,00993008 (rel: 0,00117) 9,01703e-05\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 0,1250\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,00992995 (rel: 1,30e-05) 9,36167e-05\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,00992975 (rel: 2,04e-05) 3,77463e-05\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,00992967 (rel: 7,66e-06) 1,97084e-05\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,00992964 (rel: 2,80e-06) 5,26279e-06\n",
      "23/03/25 03:25:32 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:25:32 INFO OWLQN: Val and Grad Norm: 0,00992964 (rel: 6,45e-09) 3,69978e-06\n",
      "23/03/25 03:25:33 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:33 INFO OWLQN: Val and Grad Norm: 0,00992964 (rel: 1,14e-08) 1,96903e-06\n",
      "23/03/25 03:25:33 INFO OWLQN: Converged because max iterations reached\n",
      "23/03/25 03:25:33 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:33 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:34 INFO OWLQN: Step Size: 32,13\n",
      "23/03/25 03:25:34 INFO OWLQN: Val and Grad Norm: 0,0122920 (rel: 0,0500) 0,00340841\n",
      "23/03/25 03:25:34 INFO OWLQN: Step Size: 0,1250\n",
      "23/03/25 03:25:34 INFO OWLQN: Val and Grad Norm: 0,0121422 (rel: 0,0122) 0,00135533\n",
      "23/03/25 03:25:34 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:34 INFO OWLQN: Val and Grad Norm: 0,0121148 (rel: 0,00225) 0,00161797\n",
      "23/03/25 03:25:34 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:34 INFO OWLQN: Val and Grad Norm: 0,0121054 (rel: 0,000779) 0,00259678\n",
      "23/03/25 03:25:34 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:34 INFO OWLQN: Val and Grad Norm: 0,0120621 (rel: 0,00358) 0,000648888\n",
      "23/03/25 03:25:34 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:34 INFO OWLQN: Val and Grad Norm: 0,0120552 (rel: 0,000568) 0,00116812\n",
      "23/03/25 03:25:34 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:34 INFO OWLQN: Val and Grad Norm: 0,0120507 (rel: 0,000375) 0,000859944\n",
      "23/03/25 03:25:34 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:34 INFO OWLQN: Val and Grad Norm: 0,0120477 (rel: 0,000249) 0,00129039\n",
      "23/03/25 03:25:34 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:34 INFO OWLQN: Val and Grad Norm: 0,0120341 (rel: 0,00113) 0,000233306\n",
      "23/03/25 03:25:35 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:35 INFO OWLQN: Val and Grad Norm: 0,0120300 (rel: 0,000335) 0,000271509\n",
      "23/03/25 03:25:35 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:35 INFO OWLQN: Val and Grad Norm: 0,0120293 (rel: 6,04e-05) 0,000371911\n",
      "23/03/25 03:25:35 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:35 INFO OWLQN: Val and Grad Norm: 0,0120272 (rel: 0,000174) 0,000217403\n",
      "23/03/25 03:25:35 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:35 INFO OWLQN: Val and Grad Norm: 0,0120267 (rel: 4,00e-05) 0,000224084\n",
      "23/03/25 03:25:35 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:35 INFO OWLQN: Val and Grad Norm: 0,0120265 (rel: 1,62e-05) 0,000281518\n",
      "23/03/25 03:25:35 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:35 INFO OWLQN: Val and Grad Norm: 0,0120259 (rel: 5,50e-05) 0,000215394\n",
      "23/03/25 03:25:35 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:35 INFO OWLQN: Val and Grad Norm: 0,0120254 (rel: 3,90e-05) 0,000134444\n",
      "23/03/25 03:25:35 INFO OWLQN: Step Size: 2,100\n",
      "23/03/25 03:25:35 INFO OWLQN: Val and Grad Norm: 0,0120244 (rel: 8,54e-05) 0,000115582\n",
      "23/03/25 03:25:35 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:35 INFO OWLQN: Val and Grad Norm: 0,0120215 (rel: 0,000241) 0,000150284\n",
      "23/03/25 03:25:35 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:25:35 INFO OWLQN: Val and Grad Norm: 0,0120214 (rel: 5,40e-06) 0,000128322\n",
      "23/03/25 03:25:35 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:35 INFO OWLQN: Val and Grad Norm: 0,0120213 (rel: 9,56e-06) 6,93101e-05\n",
      "23/03/25 03:25:35 INFO OWLQN: Converged because max iterations reached\n",
      "23/03/25 03:25:36 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:36 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:37 INFO LBFGS: Step Size: 33,04\n",
      "23/03/25 03:25:37 INFO LBFGS: Val and Grad Norm: 0,0124009 (rel: 0,0416) 0,0146681\n",
      "23/03/25 03:25:37 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:37 INFO LBFGS: Val and Grad Norm: 0,00840514 (rel: 0,322) 0,00973508\n",
      "23/03/25 03:25:37 INFO StrongWolfeLineSearch: Line search t: 0.44398297929103914 fval: 0.006551533655429769 rhs: 0.008404860644154324 cdd: -0.0014489826697765213\n",
      "23/03/25 03:25:37 INFO LBFGS: Step Size: 0,4440\n",
      "23/03/25 03:25:37 INFO LBFGS: Val and Grad Norm: 0,00655153 (rel: 0,221) 0,00256710\n",
      "23/03/25 03:25:37 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:37 INFO LBFGS: Val and Grad Norm: 0,00645028 (rel: 0,0155) 0,00322521\n",
      "23/03/25 03:25:37 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:37 INFO LBFGS: Val and Grad Norm: 0,00638050 (rel: 0,0108) 0,000857616\n",
      "23/03/25 03:25:37 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:37 INFO LBFGS: Val and Grad Norm: 0,00635989 (rel: 0,00323) 0,000782793\n",
      "23/03/25 03:25:37 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:37 INFO LBFGS: Val and Grad Norm: 0,00630519 (rel: 0,00860) 0,000886009\n",
      "23/03/25 03:25:37 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:37 INFO LBFGS: Val and Grad Norm: 0,00619913 (rel: 0,0168) 0,000862107\n",
      "23/03/25 03:25:37 INFO StrongWolfeLineSearch: Line search t: 0.4849344958945426 fval: 0.006174017613898907 rhs: 0.006199119902217561 cdd: 4.380525514197163E-9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 03:25:37 INFO LBFGS: Step Size: 0,4849\n",
      "23/03/25 03:25:37 INFO LBFGS: Val and Grad Norm: 0,00617402 (rel: 0,00405) 0,000727022\n",
      "23/03/25 03:25:37 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:37 INFO LBFGS: Val and Grad Norm: 0,00615038 (rel: 0,00383) 0,000157010\n",
      "23/03/25 03:25:37 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:37 INFO LBFGS: Val and Grad Norm: 0,00614988 (rel: 8,09e-05) 1,81088e-05\n",
      "23/03/25 03:25:37 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:37 INFO LBFGS: Val and Grad Norm: 0,00614988 (rel: 1,19e-06) 4,76980e-06\n",
      "23/03/25 03:25:37 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:37 INFO LBFGS: Val and Grad Norm: 0,00614988 (rel: 1,07e-07) 5,94630e-07\n",
      "23/03/25 03:25:37 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:37 INFO LBFGS: Val and Grad Norm: 0,00614988 (rel: 1,17e-09) 1,83626e-07\n",
      "23/03/25 03:25:37 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:37 INFO LBFGS: Val and Grad Norm: 0,00614988 (rel: 1,05e-10) 1,72886e-08\n",
      "23/03/25 03:25:37 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:37 INFO LBFGS: Val and Grad Norm: 0,00614988 (rel: 1,50e-12) 9,46172e-09\n",
      "23/03/25 03:25:37 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:25:38 INFO StrongWolfeLineSearch: Line search t: 5.842202960675703 fval: 0.009618214091292477 rhs: 0.012938721118997396 cdd: -3.713617878698192E-5\n",
      "23/03/25 03:25:38 INFO LBFGS: Step Size: 5,842\n",
      "23/03/25 03:25:38 INFO LBFGS: Val and Grad Norm: 0,00961821 (rel: 0,257) 0,00250205\n",
      "23/03/25 03:25:38 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:38 INFO LBFGS: Val and Grad Norm: 0,00959418 (rel: 0,00250) 0,00108791\n",
      "23/03/25 03:25:38 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:38 INFO LBFGS: Val and Grad Norm: 0,00959008 (rel: 0,000427) 0,000498566\n",
      "23/03/25 03:25:38 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:38 INFO LBFGS: Val and Grad Norm: 0,00958922 (rel: 8,92e-05) 0,000323923\n",
      "23/03/25 03:25:38 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:38 INFO LBFGS: Val and Grad Norm: 0,00958747 (rel: 0,000182) 0,000500035\n",
      "23/03/25 03:25:38 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:38 INFO LBFGS: Val and Grad Norm: 0,00958398 (rel: 0,000364) 0,000954644\n",
      "23/03/25 03:25:38 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:38 INFO LBFGS: Val and Grad Norm: 0,00957695 (rel: 0,000733) 0,00143349\n",
      "23/03/25 03:25:38 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:38 INFO LBFGS: Val and Grad Norm: 0,00956768 (rel: 0,000969) 0,00144266\n",
      "23/03/25 03:25:38 INFO StrongWolfeLineSearch: Line search t: 0.13594763760194728 fval: 0.009566549436697302 rhs: 0.009567675873940728 cdd: -9.40002037675341E-9\n",
      "23/03/25 03:25:38 INFO LBFGS: Step Size: 0,1359\n",
      "23/03/25 03:25:38 INFO LBFGS: Val and Grad Norm: 0,00956655 (rel: 0,000118) 0,00124901\n",
      "23/03/25 03:25:38 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:38 INFO LBFGS: Val and Grad Norm: 0,00956203 (rel: 0,000472) 0,000582060\n",
      "23/03/25 03:25:38 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:38 INFO LBFGS: Val and Grad Norm: 0,00956127 (rel: 7,98e-05) 0,000106328\n",
      "23/03/25 03:25:38 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:38 INFO LBFGS: Val and Grad Norm: 0,00956123 (rel: 4,25e-06) 7,89190e-06\n",
      "23/03/25 03:25:38 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:38 INFO LBFGS: Val and Grad Norm: 0,00956123 (rel: 1,38e-07) 1,00869e-06\n",
      "23/03/25 03:25:39 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:39 INFO LBFGS: Val and Grad Norm: 0,00956123 (rel: 6,21e-10) 4,70925e-07\n",
      "23/03/25 03:25:39 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:39 INFO LBFGS: Val and Grad Norm: 0,00956123 (rel: 1,03e-10) 1,08349e-07\n",
      "23/03/25 03:25:39 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:39 INFO LBFGS: Val and Grad Norm: 0,00956123 (rel: 6,67e-12) 7,35820e-09\n",
      "23/03/25 03:25:39 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:25:39 INFO StrongWolfeLineSearch: Line search t: 3.304353593687594 fval: 0.014951561729301299 rhs: 0.012938953549334742 cdd: 0.0021559762796151175\n",
      "23/03/25 03:25:39 INFO StrongWolfeLineSearch: Line search t: 1.0002678137470786 fval: 0.012482471316135429 rhs: 0.012939164570304732 cdd: 2.982231945513018E-6\n",
      "23/03/25 03:25:39 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:39 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 0,0353) 9,87529e-05\n",
      "23/03/25 03:25:39 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:39 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 3,89e-07) 1,10391e-06\n",
      "23/03/25 03:25:40 INFO LBFGS: Step Size: 5,063\n",
      "23/03/25 03:25:40 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 4,60e-10) 1,26574e-06\n",
      "23/03/25 03:25:40 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:40 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 5,03e-09) 6,23648e-06\n",
      "23/03/25 03:25:40 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:40 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 7,06e-09) 1,00255e-05\n",
      "23/03/25 03:25:40 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:40 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 9,10e-09) 9,86627e-06\n",
      "23/03/25 03:25:40 INFO StrongWolfeLineSearch: Line search t: 0.1 fval: 0.012482466186642473 rhs: 0.012482466192682996 cdd: 1.1117768747818986E-11\n",
      "23/03/25 03:25:40 INFO LBFGS: Step Size: 0,1000\n",
      "23/03/25 03:25:40 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 4,84e-10) 9,59993e-06\n",
      "23/03/25 03:25:40 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:40 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 4,20e-09) 4,13482e-06\n",
      "23/03/25 03:25:40 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:40 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 6,55e-10) 6,41089e-07\n",
      "23/03/25 03:25:40 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:40 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 2,87e-11) 2,15173e-08\n",
      "23/03/25 03:25:40 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:40 INFO LBFGS: Val and Grad Norm: 0,0124825 (rel: 3,53e-13) 3,44249e-09\n",
      "23/03/25 03:25:40 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:25:41 INFO OWLQN: Step Size: 7,286\n",
      "23/03/25 03:25:41 INFO OWLQN: Val and Grad Norm: 0,0114277 (rel: 0,117) 0,0129577\n",
      "23/03/25 03:25:41 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:25:41 INFO OWLQN: Val and Grad Norm: 0,0106905 (rel: 0,0645) 0,00897698\n",
      "23/03/25 03:25:41 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:41 INFO OWLQN: Val and Grad Norm: 0,0103003 (rel: 0,0365) 0,00372076\n",
      "23/03/25 03:25:41 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:41 INFO OWLQN: Val and Grad Norm: 0,0101679 (rel: 0,0129) 0,00235315\n",
      "23/03/25 03:25:41 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:41 INFO OWLQN: Val and Grad Norm: 0,0100377 (rel: 0,0128) 0,00156061\n",
      "23/03/25 03:25:41 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:41 INFO OWLQN: Val and Grad Norm: 0,0100131 (rel: 0,00245) 0,000688478\n",
      "23/03/25 03:25:41 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:41 INFO OWLQN: Val and Grad Norm: 0,00999630 (rel: 0,00168) 0,00101788\n",
      "23/03/25 03:25:41 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:41 INFO OWLQN: Val and Grad Norm: 0,00998057 (rel: 0,00157) 0,000721596\n",
      "23/03/25 03:25:41 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:41 INFO OWLQN: Val and Grad Norm: 0,00997474 (rel: 0,000584) 0,000673085\n",
      "23/03/25 03:25:41 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:41 INFO OWLQN: Val and Grad Norm: 0,00996986 (rel: 0,000489) 0,000862722\n",
      "23/03/25 03:25:41 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:41 INFO OWLQN: Val and Grad Norm: 0,00996563 (rel: 0,000424) 0,000489289\n",
      "23/03/25 03:25:41 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:41 INFO OWLQN: Val and Grad Norm: 0,00995914 (rel: 0,000652) 0,000494459\n",
      "23/03/25 03:25:41 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:41 INFO OWLQN: Val and Grad Norm: 0,00994173 (rel: 0,00175) 0,000251099\n",
      "23/03/25 03:25:41 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:41 INFO OWLQN: Val and Grad Norm: 0,00993008 (rel: 0,00117) 9,01703e-05\n",
      "23/03/25 03:25:41 INFO OWLQN: Step Size: 0,1250\n",
      "23/03/25 03:25:41 INFO OWLQN: Val and Grad Norm: 0,00992995 (rel: 1,30e-05) 9,36167e-05\n",
      "23/03/25 03:25:42 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:42 INFO OWLQN: Val and Grad Norm: 0,00992975 (rel: 2,04e-05) 3,77463e-05\n",
      "23/03/25 03:25:42 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:42 INFO OWLQN: Val and Grad Norm: 0,00992967 (rel: 7,66e-06) 1,97084e-05\n",
      "23/03/25 03:25:42 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:42 INFO OWLQN: Val and Grad Norm: 0,00992964 (rel: 2,80e-06) 5,26279e-06\n",
      "23/03/25 03:25:42 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:25:42 INFO OWLQN: Val and Grad Norm: 0,00992964 (rel: 6,45e-09) 3,69978e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 03:25:42 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:42 INFO OWLQN: Val and Grad Norm: 0,00992964 (rel: 1,14e-08) 1,96903e-06\n",
      "23/03/25 03:25:42 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:42 INFO OWLQN: Val and Grad Norm: 0,00992964 (rel: 2,53e-09) 9,46912e-07\n",
      "23/03/25 03:25:42 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:42 INFO OWLQN: Val and Grad Norm: 0,00992964 (rel: 1,25e-09) 7,86899e-07\n",
      "23/03/25 03:25:42 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:42 INFO OWLQN: Val and Grad Norm: 0,00992964 (rel: 3,54e-09) 1,21341e-07\n",
      "23/03/25 03:25:42 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:25:42 INFO OWLQN: Val and Grad Norm: 0,00992964 (rel: 2,34e-11) 7,27495e-08\n",
      "23/03/25 03:25:42 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:42 INFO OWLQN: Val and Grad Norm: 0,00992964 (rel: 3,11e-11) 6,94073e-08\n",
      "23/03/25 03:25:42 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:42 INFO OWLQN: Val and Grad Norm: 0,00992964 (rel: 4,27e-12) 5,04886e-09\n",
      "23/03/25 03:25:42 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:43 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:43 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:44 INFO OWLQN: Step Size: 32,13\n",
      "23/03/25 03:25:44 INFO OWLQN: Val and Grad Norm: 0,0122920 (rel: 0,0500) 0,00340841\n",
      "23/03/25 03:25:44 INFO OWLQN: Step Size: 0,1250\n",
      "23/03/25 03:25:44 INFO OWLQN: Val and Grad Norm: 0,0121422 (rel: 0,0122) 0,00135533\n",
      "23/03/25 03:25:44 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:44 INFO OWLQN: Val and Grad Norm: 0,0121148 (rel: 0,00225) 0,00161797\n",
      "23/03/25 03:25:44 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:44 INFO OWLQN: Val and Grad Norm: 0,0121054 (rel: 0,000779) 0,00259678\n",
      "23/03/25 03:25:44 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:44 INFO OWLQN: Val and Grad Norm: 0,0120621 (rel: 0,00358) 0,000648888\n",
      "23/03/25 03:25:44 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:44 INFO OWLQN: Val and Grad Norm: 0,0120552 (rel: 0,000568) 0,00116812\n",
      "23/03/25 03:25:44 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:44 INFO OWLQN: Val and Grad Norm: 0,0120507 (rel: 0,000375) 0,000859944\n",
      "23/03/25 03:25:44 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:44 INFO OWLQN: Val and Grad Norm: 0,0120477 (rel: 0,000249) 0,00129039\n",
      "23/03/25 03:25:44 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:44 INFO OWLQN: Val and Grad Norm: 0,0120341 (rel: 0,00113) 0,000233306\n",
      "23/03/25 03:25:44 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:44 INFO OWLQN: Val and Grad Norm: 0,0120300 (rel: 0,000335) 0,000271509\n",
      "23/03/25 03:25:44 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:44 INFO OWLQN: Val and Grad Norm: 0,0120293 (rel: 6,04e-05) 0,000371911\n",
      "23/03/25 03:25:44 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:44 INFO OWLQN: Val and Grad Norm: 0,0120272 (rel: 0,000174) 0,000217403\n",
      "23/03/25 03:25:44 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:44 INFO OWLQN: Val and Grad Norm: 0,0120267 (rel: 4,00e-05) 0,000224084\n",
      "23/03/25 03:25:44 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:44 INFO OWLQN: Val and Grad Norm: 0,0120265 (rel: 1,62e-05) 0,000281518\n",
      "23/03/25 03:25:44 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:44 INFO OWLQN: Val and Grad Norm: 0,0120259 (rel: 5,50e-05) 0,000215394\n",
      "23/03/25 03:25:44 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:44 INFO OWLQN: Val and Grad Norm: 0,0120254 (rel: 3,90e-05) 0,000134444\n",
      "23/03/25 03:25:45 INFO OWLQN: Step Size: 2,100\n",
      "23/03/25 03:25:45 INFO OWLQN: Val and Grad Norm: 0,0120244 (rel: 8,54e-05) 0,000115582\n",
      "23/03/25 03:25:45 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:45 INFO OWLQN: Val and Grad Norm: 0,0120215 (rel: 0,000241) 0,000150284\n",
      "23/03/25 03:25:45 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:25:45 INFO OWLQN: Val and Grad Norm: 0,0120214 (rel: 5,40e-06) 0,000128322\n",
      "23/03/25 03:25:45 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:45 INFO OWLQN: Val and Grad Norm: 0,0120213 (rel: 9,56e-06) 6,93101e-05\n",
      "23/03/25 03:25:45 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:45 INFO OWLQN: Val and Grad Norm: 0,0120213 (rel: 2,55e-06) 4,01348e-05\n",
      "23/03/25 03:25:45 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:45 INFO OWLQN: Val and Grad Norm: 0,0120213 (rel: 9,16e-07) 2,10550e-05\n",
      "23/03/25 03:25:45 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:45 INFO OWLQN: Val and Grad Norm: 0,0120213 (rel: 2,60e-07) 1,20397e-05\n",
      "23/03/25 03:25:45 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:45 INFO OWLQN: Val and Grad Norm: 0,0120213 (rel: 9,02e-08) 5,02930e-06\n",
      "23/03/25 03:25:45 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:45 INFO OWLQN: Val and Grad Norm: 0,0120213 (rel: 1,93e-08) 3,29713e-06\n",
      "23/03/25 03:25:45 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:45 INFO OWLQN: Val and Grad Norm: 0,0120213 (rel: 9,89e-09) 1,86553e-06\n",
      "23/03/25 03:25:45 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:45 INFO OWLQN: Val and Grad Norm: 0,0120213 (rel: 9,78e-09) 1,46525e-06\n",
      "23/03/25 03:25:45 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:45 INFO OWLQN: Val and Grad Norm: 0,0120213 (rel: 2,54e-08) 3,12564e-07\n",
      "23/03/25 03:25:45 INFO OWLQN: Step Size: 0,1250\n",
      "23/03/25 03:25:45 INFO OWLQN: Val and Grad Norm: 0,0120213 (rel: 2,81e-11) 2,61207e-07\n",
      "23/03/25 03:25:45 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:45 INFO OWLQN: Val and Grad Norm: 0,0120213 (rel: 5,23e-11) 1,45188e-07\n",
      "23/03/25 03:25:45 INFO OWLQN: Converged because max iterations reached\n",
      "23/03/25 03:25:46 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:47 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:48 INFO LBFGS: Step Size: 32,44\n",
      "23/03/25 03:25:48 INFO LBFGS: Val and Grad Norm: 0,0127550 (rel: 0,00734) 0,0154403\n",
      "23/03/25 03:25:48 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:48 INFO LBFGS: Val and Grad Norm: 0,00847962 (rel: 0,335) 0,00992973\n",
      "23/03/25 03:25:48 INFO StrongWolfeLineSearch: Line search t: 0.5025712121032229 fval: 0.006612357480517646 rhs: 0.008479317902127857 cdd: -8.937975576466893E-4\n",
      "23/03/25 03:25:48 INFO LBFGS: Step Size: 0,5026\n",
      "23/03/25 03:25:48 INFO LBFGS: Val and Grad Norm: 0,00661236 (rel: 0,220) 0,00213514\n",
      "23/03/25 03:25:48 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:48 INFO LBFGS: Val and Grad Norm: 0,00651490 (rel: 0,0147) 0,00214872\n",
      "23/03/25 03:25:48 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:48 INFO LBFGS: Val and Grad Norm: 0,00646412 (rel: 0,00780) 0,000766708\n",
      "23/03/25 03:25:48 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:48 INFO LBFGS: Val and Grad Norm: 0,00644396 (rel: 0,00312) 0,000852580\n",
      "23/03/25 03:25:48 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:48 INFO LBFGS: Val and Grad Norm: 0,00639848 (rel: 0,00706) 0,00109109\n",
      "23/03/25 03:25:48 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:48 INFO LBFGS: Val and Grad Norm: 0,00630593 (rel: 0,0145) 0,00116457\n",
      "23/03/25 03:25:48 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:48 INFO LBFGS: Val and Grad Norm: 0,00629379 (rel: 0,00193) 0,00157249\n",
      "23/03/25 03:25:48 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:48 INFO LBFGS: Val and Grad Norm: 0,00626416 (rel: 0,00471) 0,000443176\n",
      "23/03/25 03:25:48 INFO LBFGS: Converged because max iterations reached\n",
      "23/03/25 03:25:49 INFO StrongWolfeLineSearch: Line search t: 5.7425378620536165 fval: 0.009493883361224791 rhs: 0.012848779660613293 cdd: -4.0931465539235645E-6\n",
      "23/03/25 03:25:49 INFO LBFGS: Step Size: 5,743\n",
      "23/03/25 03:25:49 INFO LBFGS: Val and Grad Norm: 0,00949388 (rel: 0,261) 0,00219645\n",
      "23/03/25 03:25:49 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:49 INFO LBFGS: Val and Grad Norm: 0,00947466 (rel: 0,00202) 0,000856520\n",
      "23/03/25 03:25:49 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:49 INFO LBFGS: Val and Grad Norm: 0,00947039 (rel: 0,000451) 0,000333890\n",
      "23/03/25 03:25:49 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:49 INFO LBFGS: Val and Grad Norm: 0,00946914 (rel: 0,000131) 0,000367849\n",
      "23/03/25 03:25:49 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:49 INFO LBFGS: Val and Grad Norm: 0,00945872 (rel: 0,00110) 0,000885622\n",
      "23/03/25 03:25:49 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:49 INFO LBFGS: Val and Grad Norm: 0,00944848 (rel: 0,00108) 0,00106827\n",
      "23/03/25 03:25:50 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:50 INFO LBFGS: Val and Grad Norm: 0,00944002 (rel: 0,000895) 0,000599044\n",
      "23/03/25 03:25:50 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:50 INFO LBFGS: Val and Grad Norm: 0,00943948 (rel: 5,75e-05) 0,000516713\n",
      "23/03/25 03:25:50 INFO LBFGS: Step Size: 1,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 03:25:50 INFO LBFGS: Val and Grad Norm: 0,00943825 (rel: 0,000130) 8,40876e-05\n",
      "23/03/25 03:25:50 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:50 INFO LBFGS: Val and Grad Norm: 0,00943823 (rel: 2,78e-06) 2,57943e-05\n",
      "23/03/25 03:25:50 INFO LBFGS: Converged because max iterations reached\n",
      "23/03/25 03:25:50 INFO StrongWolfeLineSearch: Line search t: 3.2441267948325114 fval: 0.014809805207892334 rhs: 0.012849017053802531 cdd: 0.002184597449264108\n",
      "23/03/25 03:25:50 INFO StrongWolfeLineSearch: Line search t: 1.0003976998603976 fval: 0.012375517884951092 rhs: 0.012849230247705101 cdd: 3.475931782170623E-6\n",
      "23/03/25 03:25:50 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:50 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 0,0369) 0,000112994\n",
      "23/03/25 03:25:50 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:50 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 5,13e-07) 1,36566e-06\n",
      "23/03/25 03:25:51 INFO LBFGS: Step Size: 5,063\n",
      "23/03/25 03:25:51 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 7,04e-10) 1,59061e-06\n",
      "23/03/25 03:25:51 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:51 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 6,92e-09) 7,38118e-06\n",
      "23/03/25 03:25:51 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:51 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 1,04e-08) 1,22641e-05\n",
      "23/03/25 03:25:51 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:51 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 1,42e-08) 1,28126e-05\n",
      "23/03/25 03:25:51 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:51 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 8,56e-09) 5,35522e-06\n",
      "23/03/25 03:25:51 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:51 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 7,99e-10) 2,72026e-06\n",
      "23/03/25 03:25:51 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:51 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 3,53e-10) 1,41055e-07\n",
      "23/03/25 03:25:51 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:51 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 2,51e-12) 2,27788e-08\n",
      "23/03/25 03:25:51 INFO LBFGS: Converged because max iterations reached\n",
      "23/03/25 03:25:52 INFO OWLQN: Step Size: 7,153\n",
      "23/03/25 03:25:52 INFO OWLQN: Val and Grad Norm: 0,0112666 (rel: 0,123) 0,0132053\n",
      "23/03/25 03:25:52 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:25:52 INFO OWLQN: Val and Grad Norm: 0,0106281 (rel: 0,0567) 0,00893320\n",
      "23/03/25 03:25:52 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:52 INFO OWLQN: Val and Grad Norm: 0,0102624 (rel: 0,0344) 0,00380938\n",
      "23/03/25 03:25:52 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:52 INFO OWLQN: Val and Grad Norm: 0,0101522 (rel: 0,0107) 0,00235829\n",
      "23/03/25 03:25:52 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:52 INFO OWLQN: Val and Grad Norm: 0,0100376 (rel: 0,0113) 0,000944508\n",
      "23/03/25 03:25:52 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:52 INFO OWLQN: Val and Grad Norm: 0,0100067 (rel: 0,00307) 0,00146766\n",
      "23/03/25 03:25:52 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:52 INFO OWLQN: Val and Grad Norm: 0,00998919 (rel: 0,00175) 0,000444854\n",
      "23/03/25 03:25:52 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:52 INFO OWLQN: Val and Grad Norm: 0,00998257 (rel: 0,000663) 0,000558930\n",
      "23/03/25 03:25:52 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:52 INFO OWLQN: Val and Grad Norm: 0,00997480 (rel: 0,000778) 0,00120140\n",
      "23/03/25 03:25:52 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:52 INFO OWLQN: Val and Grad Norm: 0,00996505 (rel: 0,000977) 0,000683176\n",
      "23/03/25 03:25:52 INFO OWLQN: Converged because max iterations reached\n",
      "23/03/25 03:25:53 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:53 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:54 INFO OWLQN: Step Size: 31,55\n",
      "23/03/25 03:25:54 INFO OWLQN: Val and Grad Norm: 0,0121457 (rel: 0,0548) 0,00329858\n",
      "23/03/25 03:25:54 INFO OWLQN: Step Size: 0,1250\n",
      "23/03/25 03:25:54 INFO OWLQN: Val and Grad Norm: 0,0120319 (rel: 0,00937) 0,00124397\n",
      "23/03/25 03:25:54 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:54 INFO OWLQN: Val and Grad Norm: 0,0120124 (rel: 0,00162) 0,00153875\n",
      "23/03/25 03:25:54 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:54 INFO OWLQN: Val and Grad Norm: 0,0119646 (rel: 0,00397) 0,000242946\n",
      "23/03/25 03:25:54 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:54 INFO OWLQN: Val and Grad Norm: 0,0119635 (rel: 9,24e-05) 0,000517663\n",
      "23/03/25 03:25:54 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:25:54 INFO OWLQN: Val and Grad Norm: 0,0119621 (rel: 0,000124) 0,000221082\n",
      "23/03/25 03:25:54 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:25:54 INFO OWLQN: Val and Grad Norm: 0,0119608 (rel: 0,000103) 0,000641184\n",
      "23/03/25 03:25:54 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:25:54 INFO OWLQN: Val and Grad Norm: 0,0119581 (rel: 0,000225) 0,000232653\n",
      "23/03/25 03:25:54 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:25:54 INFO OWLQN: Val and Grad Norm: 0,0119573 (rel: 6,71e-05) 0,000256217\n",
      "23/03/25 03:25:54 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:25:54 INFO OWLQN: Val and Grad Norm: 0,0119571 (rel: 1,56e-05) 0,000327052\n",
      "23/03/25 03:25:54 INFO OWLQN: Converged because max iterations reached\n",
      "23/03/25 03:25:55 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:55 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 32,44\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,0127550 (rel: 0,00734) 0,0154403\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00847962 (rel: 0,335) 0,00992973\n",
      "23/03/25 03:25:56 INFO StrongWolfeLineSearch: Line search t: 0.5025712121032229 fval: 0.006612357480517645 rhs: 0.008479317902127857 cdd: -8.937975576466891E-4\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 0,5026\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00661236 (rel: 0,220) 0,00213514\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00651490 (rel: 0,0147) 0,00214872\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00646412 (rel: 0,00780) 0,000766708\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00644396 (rel: 0,00312) 0,000852580\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00639848 (rel: 0,00706) 0,00109109\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00630593 (rel: 0,0145) 0,00116457\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00629379 (rel: 0,00193) 0,00157249\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00626416 (rel: 0,00471) 0,000443176\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00625887 (rel: 0,000844) 0,000231547\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00625761 (rel: 0,000201) 0,000111179\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00625722 (rel: 6,25e-05) 3,41775e-05\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00625720 (rel: 3,45e-06) 1,23298e-05\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00625720 (rel: 3,93e-07) 7,29175e-07\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00625720 (rel: 1,73e-09) 1,85759e-07\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00625720 (rel: 1,88e-10) 6,73292e-08\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00625720 (rel: 2,18e-11) 3,34071e-08\n",
      "23/03/25 03:25:56 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:56 INFO LBFGS: Val and Grad Norm: 0,00625720 (rel: 3,16e-12) 6,58153e-09\n",
      "23/03/25 03:25:56 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:25:57 INFO StrongWolfeLineSearch: Line search t: 5.7425378620536165 fval: 0.009493883361224791 rhs: 0.012848779660613293 cdd: -4.0931465539236424E-6\n",
      "23/03/25 03:25:57 INFO LBFGS: Step Size: 5,743\n",
      "23/03/25 03:25:57 INFO LBFGS: Val and Grad Norm: 0,00949388 (rel: 0,261) 0,00219645\n",
      "23/03/25 03:25:57 INFO LBFGS: Step Size: 1,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 03:25:57 INFO LBFGS: Val and Grad Norm: 0,00947466 (rel: 0,00202) 0,000856520\n",
      "23/03/25 03:25:57 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:57 INFO LBFGS: Val and Grad Norm: 0,00947039 (rel: 0,000451) 0,000333890\n",
      "23/03/25 03:25:57 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:57 INFO LBFGS: Val and Grad Norm: 0,00946914 (rel: 0,000131) 0,000367849\n",
      "23/03/25 03:25:57 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:57 INFO LBFGS: Val and Grad Norm: 0,00945872 (rel: 0,00110) 0,000885622\n",
      "23/03/25 03:25:57 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:57 INFO LBFGS: Val and Grad Norm: 0,00944848 (rel: 0,00108) 0,00106827\n",
      "23/03/25 03:25:57 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:57 INFO LBFGS: Val and Grad Norm: 0,00944002 (rel: 0,000895) 0,000599044\n",
      "23/03/25 03:25:57 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:57 INFO LBFGS: Val and Grad Norm: 0,00943948 (rel: 5,75e-05) 0,000516713\n",
      "23/03/25 03:25:57 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:57 INFO LBFGS: Val and Grad Norm: 0,00943825 (rel: 0,000130) 8,40876e-05\n",
      "23/03/25 03:25:58 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:58 INFO LBFGS: Val and Grad Norm: 0,00943823 (rel: 2,78e-06) 2,57943e-05\n",
      "23/03/25 03:25:58 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:58 INFO LBFGS: Val and Grad Norm: 0,00943823 (rel: 2,51e-07) 3,39531e-06\n",
      "23/03/25 03:25:58 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:58 INFO LBFGS: Val and Grad Norm: 0,00943822 (rel: 4,65e-09) 1,30819e-07\n",
      "23/03/25 03:25:58 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:58 INFO LBFGS: Val and Grad Norm: 0,00943822 (rel: 8,24e-12) 1,64706e-08\n",
      "23/03/25 03:25:58 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:58 INFO LBFGS: Val and Grad Norm: 0,00943822 (rel: 1,31e-13) 1,93276e-10\n",
      "23/03/25 03:25:58 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:25:58 INFO StrongWolfeLineSearch: Line search t: 3.2441267948325114 fval: 0.014809805207892334 rhs: 0.012849017053802531 cdd: 0.002184597449264108\n",
      "23/03/25 03:25:58 INFO StrongWolfeLineSearch: Line search t: 1.0003976998603976 fval: 0.012375517884951092 rhs: 0.012849230247705101 cdd: 3.4759317821706267E-6\n",
      "23/03/25 03:25:58 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:58 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 0,0369) 0,000112994\n",
      "23/03/25 03:25:58 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:58 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 5,13e-07) 1,36566e-06\n",
      "23/03/25 03:25:59 INFO LBFGS: Step Size: 5,063\n",
      "23/03/25 03:25:59 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 7,04e-10) 1,59061e-06\n",
      "23/03/25 03:25:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:59 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 6,92e-09) 7,38118e-06\n",
      "23/03/25 03:25:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:59 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 1,04e-08) 1,22641e-05\n",
      "23/03/25 03:25:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:59 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 1,42e-08) 1,28126e-05\n",
      "23/03/25 03:25:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:59 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 8,56e-09) 5,35522e-06\n",
      "23/03/25 03:25:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:59 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 7,99e-10) 2,72026e-06\n",
      "23/03/25 03:25:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:59 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 3,53e-10) 1,41055e-07\n",
      "23/03/25 03:25:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:59 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 2,51e-12) 2,27788e-08\n",
      "23/03/25 03:25:59 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:25:59 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 5,07e-14) 5,00251e-10\n",
      "23/03/25 03:25:59 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:26:00 INFO OWLQN: Step Size: 7,153\n",
      "23/03/25 03:26:00 INFO OWLQN: Val and Grad Norm: 0,0112666 (rel: 0,123) 0,0132053\n",
      "23/03/25 03:26:00 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:26:00 INFO OWLQN: Val and Grad Norm: 0,0106281 (rel: 0,0567) 0,00893320\n",
      "23/03/25 03:26:00 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:00 INFO OWLQN: Val and Grad Norm: 0,0102624 (rel: 0,0344) 0,00380938\n",
      "23/03/25 03:26:00 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:00 INFO OWLQN: Val and Grad Norm: 0,0101522 (rel: 0,0107) 0,00235829\n",
      "23/03/25 03:26:00 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:00 INFO OWLQN: Val and Grad Norm: 0,0100376 (rel: 0,0113) 0,000944508\n",
      "23/03/25 03:26:00 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:00 INFO OWLQN: Val and Grad Norm: 0,0100067 (rel: 0,00307) 0,00146766\n",
      "23/03/25 03:26:00 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:00 INFO OWLQN: Val and Grad Norm: 0,00998919 (rel: 0,00175) 0,000444854\n",
      "23/03/25 03:26:00 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:00 INFO OWLQN: Val and Grad Norm: 0,00998257 (rel: 0,000663) 0,000558930\n",
      "23/03/25 03:26:00 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:00 INFO OWLQN: Val and Grad Norm: 0,00997480 (rel: 0,000778) 0,00120140\n",
      "23/03/25 03:26:00 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:00 INFO OWLQN: Val and Grad Norm: 0,00996505 (rel: 0,000977) 0,000683176\n",
      "23/03/25 03:26:00 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:00 INFO OWLQN: Val and Grad Norm: 0,00995933 (rel: 0,000574) 0,000851632\n",
      "23/03/25 03:26:00 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:00 INFO OWLQN: Val and Grad Norm: 0,00995330 (rel: 0,000606) 0,000464996\n",
      "23/03/25 03:26:00 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:00 INFO OWLQN: Val and Grad Norm: 0,00994612 (rel: 0,000721) 0,000298339\n",
      "23/03/25 03:26:00 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:00 INFO OWLQN: Val and Grad Norm: 0,00993439 (rel: 0,00118) 0,000263563\n",
      "23/03/25 03:26:01 INFO OWLQN: Step Size: 0,1250\n",
      "23/03/25 03:26:01 INFO OWLQN: Val and Grad Norm: 0,00993332 (rel: 0,000107) 0,000327402\n",
      "23/03/25 03:26:01 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:01 INFO OWLQN: Val and Grad Norm: 0,00993188 (rel: 0,000145) 0,000169534\n",
      "23/03/25 03:26:01 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:01 INFO OWLQN: Val and Grad Norm: 0,00993152 (rel: 3,62e-05) 0,000184836\n",
      "23/03/25 03:26:01 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:01 INFO OWLQN: Val and Grad Norm: 0,00993126 (rel: 2,61e-05) 8,97832e-05\n",
      "23/03/25 03:26:01 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:01 INFO OWLQN: Val and Grad Norm: 0,00993110 (rel: 1,60e-05) 7,63532e-05\n",
      "23/03/25 03:26:01 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:01 INFO OWLQN: Val and Grad Norm: 0,00993106 (rel: 4,59e-06) 8,17323e-05\n",
      "23/03/25 03:26:01 INFO OWLQN: Converged because max iterations reached\n",
      "23/03/25 03:26:02 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:26:02 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:26:02 INFO OWLQN: Step Size: 31,55\n",
      "23/03/25 03:26:02 INFO OWLQN: Val and Grad Norm: 0,0121457 (rel: 0,0548) 0,00329858\n",
      "23/03/25 03:26:03 INFO OWLQN: Step Size: 0,1250\n",
      "23/03/25 03:26:03 INFO OWLQN: Val and Grad Norm: 0,0120319 (rel: 0,00937) 0,00124397\n",
      "23/03/25 03:26:03 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:03 INFO OWLQN: Val and Grad Norm: 0,0120124 (rel: 0,00162) 0,00153875\n",
      "23/03/25 03:26:03 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:03 INFO OWLQN: Val and Grad Norm: 0,0119646 (rel: 0,00397) 0,000242946\n",
      "23/03/25 03:26:03 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:26:03 INFO OWLQN: Val and Grad Norm: 0,0119635 (rel: 9,24e-05) 0,000517663\n",
      "23/03/25 03:26:03 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:26:03 INFO OWLQN: Val and Grad Norm: 0,0119621 (rel: 0,000124) 0,000221082\n",
      "23/03/25 03:26:03 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:03 INFO OWLQN: Val and Grad Norm: 0,0119608 (rel: 0,000103) 0,000641184\n",
      "23/03/25 03:26:03 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:26:03 INFO OWLQN: Val and Grad Norm: 0,0119581 (rel: 0,000225) 0,000232653\n",
      "23/03/25 03:26:03 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:26:03 INFO OWLQN: Val and Grad Norm: 0,0119573 (rel: 6,71e-05) 0,000256217\n",
      "23/03/25 03:26:03 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:26:03 INFO OWLQN: Val and Grad Norm: 0,0119571 (rel: 1,56e-05) 0,000327052\n",
      "23/03/25 03:26:03 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:26:03 INFO OWLQN: Val and Grad Norm: 0,0119564 (rel: 6,08e-05) 0,000261503\n",
      "23/03/25 03:26:03 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:26:03 INFO OWLQN: Val and Grad Norm: 0,0119560 (rel: 3,58e-05) 0,000184998\n",
      "23/03/25 03:26:03 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:26:03 INFO OWLQN: Val and Grad Norm: 0,0119558 (rel: 1,86e-05) 0,000165286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 03:26:03 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:26:03 INFO OWLQN: Val and Grad Norm: 0,0119556 (rel: 1,38e-05) 0,000201470\n",
      "23/03/25 03:26:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:04 INFO OWLQN: Val and Grad Norm: 0,0119552 (rel: 3,26e-05) 0,000200429\n",
      "23/03/25 03:26:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:04 INFO OWLQN: Val and Grad Norm: 0,0119547 (rel: 4,43e-05) 0,000169831\n",
      "23/03/25 03:26:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:04 INFO OWLQN: Val and Grad Norm: 0,0119539 (rel: 6,29e-05) 0,000173204\n",
      "23/03/25 03:26:04 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:26:04 INFO OWLQN: Val and Grad Norm: 0,0119517 (rel: 0,000187) 0,000328901\n",
      "23/03/25 03:26:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:04 INFO OWLQN: Val and Grad Norm: 0,0119504 (rel: 0,000106) 0,000310604\n",
      "23/03/25 03:26:04 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:04 INFO OWLQN: Val and Grad Norm: 0,0119501 (rel: 2,40e-05) 0,000253362\n",
      "23/03/25 03:26:04 INFO OWLQN: Converged because max iterations reached\n",
      "23/03/25 03:26:04 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:26:05 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:26:05 INFO LBFGS: Step Size: 32,44\n",
      "23/03/25 03:26:05 INFO LBFGS: Val and Grad Norm: 0,0127550 (rel: 0,00734) 0,0154403\n",
      "23/03/25 03:26:05 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:05 INFO LBFGS: Val and Grad Norm: 0,00847962 (rel: 0,335) 0,00992973\n",
      "23/03/25 03:26:05 INFO StrongWolfeLineSearch: Line search t: 0.5025712121032229 fval: 0.006612357480517646 rhs: 0.008479317902127857 cdd: -8.937975576466877E-4\n",
      "23/03/25 03:26:05 INFO LBFGS: Step Size: 0,5026\n",
      "23/03/25 03:26:05 INFO LBFGS: Val and Grad Norm: 0,00661236 (rel: 0,220) 0,00213514\n",
      "23/03/25 03:26:05 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:05 INFO LBFGS: Val and Grad Norm: 0,00651490 (rel: 0,0147) 0,00214872\n",
      "23/03/25 03:26:05 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:05 INFO LBFGS: Val and Grad Norm: 0,00646412 (rel: 0,00780) 0,000766708\n",
      "23/03/25 03:26:05 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:05 INFO LBFGS: Val and Grad Norm: 0,00644396 (rel: 0,00312) 0,000852580\n",
      "23/03/25 03:26:05 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:05 INFO LBFGS: Val and Grad Norm: 0,00639848 (rel: 0,00706) 0,00109109\n",
      "23/03/25 03:26:05 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:05 INFO LBFGS: Val and Grad Norm: 0,00630593 (rel: 0,0145) 0,00116457\n",
      "23/03/25 03:26:05 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:05 INFO LBFGS: Val and Grad Norm: 0,00629379 (rel: 0,00193) 0,00157249\n",
      "23/03/25 03:26:05 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:05 INFO LBFGS: Val and Grad Norm: 0,00626416 (rel: 0,00471) 0,000443176\n",
      "23/03/25 03:26:06 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:06 INFO LBFGS: Val and Grad Norm: 0,00625887 (rel: 0,000844) 0,000231547\n",
      "23/03/25 03:26:06 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:06 INFO LBFGS: Val and Grad Norm: 0,00625761 (rel: 0,000201) 0,000111179\n",
      "23/03/25 03:26:06 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:06 INFO LBFGS: Val and Grad Norm: 0,00625722 (rel: 6,25e-05) 3,41775e-05\n",
      "23/03/25 03:26:06 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:06 INFO LBFGS: Val and Grad Norm: 0,00625720 (rel: 3,45e-06) 1,23298e-05\n",
      "23/03/25 03:26:06 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:06 INFO LBFGS: Val and Grad Norm: 0,00625720 (rel: 3,93e-07) 7,29175e-07\n",
      "23/03/25 03:26:06 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:06 INFO LBFGS: Val and Grad Norm: 0,00625720 (rel: 1,73e-09) 1,85759e-07\n",
      "23/03/25 03:26:06 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:06 INFO LBFGS: Val and Grad Norm: 0,00625720 (rel: 1,88e-10) 6,73292e-08\n",
      "23/03/25 03:26:06 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:06 INFO LBFGS: Val and Grad Norm: 0,00625720 (rel: 2,18e-11) 3,34071e-08\n",
      "23/03/25 03:26:06 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:06 INFO LBFGS: Val and Grad Norm: 0,00625720 (rel: 3,16e-12) 6,58153e-09\n",
      "23/03/25 03:26:06 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:26:07 INFO StrongWolfeLineSearch: Line search t: 5.742537862053613 fval: 0.00949388336122479 rhs: 0.012848779660613293 cdd: -4.093146553924617E-6\n",
      "23/03/25 03:26:07 INFO LBFGS: Step Size: 5,743\n",
      "23/03/25 03:26:07 INFO LBFGS: Val and Grad Norm: 0,00949388 (rel: 0,261) 0,00219645\n",
      "23/03/25 03:26:07 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:07 INFO LBFGS: Val and Grad Norm: 0,00947466 (rel: 0,00202) 0,000856520\n",
      "23/03/25 03:26:07 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:07 INFO LBFGS: Val and Grad Norm: 0,00947039 (rel: 0,000451) 0,000333890\n",
      "23/03/25 03:26:07 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:07 INFO LBFGS: Val and Grad Norm: 0,00946914 (rel: 0,000131) 0,000367849\n",
      "23/03/25 03:26:07 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:07 INFO LBFGS: Val and Grad Norm: 0,00945872 (rel: 0,00110) 0,000885622\n",
      "23/03/25 03:26:07 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:07 INFO LBFGS: Val and Grad Norm: 0,00944848 (rel: 0,00108) 0,00106827\n",
      "23/03/25 03:26:07 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:07 INFO LBFGS: Val and Grad Norm: 0,00944002 (rel: 0,000895) 0,000599044\n",
      "23/03/25 03:26:07 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:07 INFO LBFGS: Val and Grad Norm: 0,00943948 (rel: 5,75e-05) 0,000516713\n",
      "23/03/25 03:26:07 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:07 INFO LBFGS: Val and Grad Norm: 0,00943825 (rel: 0,000130) 8,40876e-05\n",
      "23/03/25 03:26:07 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:07 INFO LBFGS: Val and Grad Norm: 0,00943823 (rel: 2,78e-06) 2,57943e-05\n",
      "23/03/25 03:26:07 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:07 INFO LBFGS: Val and Grad Norm: 0,00943823 (rel: 2,51e-07) 3,39531e-06\n",
      "23/03/25 03:26:07 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:07 INFO LBFGS: Val and Grad Norm: 0,00943822 (rel: 4,65e-09) 1,30819e-07\n",
      "23/03/25 03:26:07 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:07 INFO LBFGS: Val and Grad Norm: 0,00943822 (rel: 8,24e-12) 1,64706e-08\n",
      "23/03/25 03:26:07 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:07 INFO LBFGS: Val and Grad Norm: 0,00943822 (rel: 1,31e-13) 1,93276e-10\n",
      "23/03/25 03:26:07 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:26:08 INFO StrongWolfeLineSearch: Line search t: 3.2441267948325105 fval: 0.01480980520789233 rhs: 0.012849017053802531 cdd: 0.002184597449264107\n",
      "23/03/25 03:26:08 INFO StrongWolfeLineSearch: Line search t: 1.000397699860398 fval: 0.012375517884951094 rhs: 0.012849230247705101 cdd: 3.475931782171018E-6\n",
      "23/03/25 03:26:08 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:08 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 0,0369) 0,000112994\n",
      "23/03/25 03:26:08 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:08 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 5,13e-07) 1,36566e-06\n",
      "23/03/25 03:26:08 INFO LBFGS: Step Size: 5,063\n",
      "23/03/25 03:26:08 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 7,04e-10) 1,59061e-06\n",
      "23/03/25 03:26:08 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:08 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 6,92e-09) 7,38118e-06\n",
      "23/03/25 03:26:08 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:08 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 1,04e-08) 1,22641e-05\n",
      "23/03/25 03:26:08 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:08 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 1,42e-08) 1,28126e-05\n",
      "23/03/25 03:26:08 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:08 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 8,56e-09) 5,35522e-06\n",
      "23/03/25 03:26:08 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:08 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 7,99e-10) 2,72026e-06\n",
      "23/03/25 03:26:08 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:08 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 3,53e-10) 1,41055e-07\n",
      "23/03/25 03:26:08 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:08 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 2,51e-12) 2,27788e-08\n",
      "23/03/25 03:26:08 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:08 INFO LBFGS: Val and Grad Norm: 0,0123755 (rel: 5,07e-14) 5,00251e-10\n",
      "23/03/25 03:26:08 INFO LBFGS: Converged because gradient converged\n",
      "23/03/25 03:26:09 INFO OWLQN: Step Size: 7,153\n",
      "23/03/25 03:26:09 INFO OWLQN: Val and Grad Norm: 0,0112666 (rel: 0,123) 0,0132053\n",
      "23/03/25 03:26:09 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:26:09 INFO OWLQN: Val and Grad Norm: 0,0106281 (rel: 0,0567) 0,00893320\n",
      "23/03/25 03:26:09 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:09 INFO OWLQN: Val and Grad Norm: 0,0102624 (rel: 0,0344) 0,00380938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 03:26:09 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:09 INFO OWLQN: Val and Grad Norm: 0,0101522 (rel: 0,0107) 0,00235829\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,0100376 (rel: 0,0113) 0,000944508\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,0100067 (rel: 0,00307) 0,00146766\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00998919 (rel: 0,00175) 0,000444854\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00998257 (rel: 0,000663) 0,000558930\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00997480 (rel: 0,000778) 0,00120140\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00996505 (rel: 0,000977) 0,000683176\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00995933 (rel: 0,000574) 0,000851632\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00995330 (rel: 0,000606) 0,000464996\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00994612 (rel: 0,000721) 0,000298339\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00993439 (rel: 0,00118) 0,000263563\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 0,1250\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00993332 (rel: 0,000107) 0,000327402\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00993188 (rel: 0,000145) 0,000169534\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00993152 (rel: 3,62e-05) 0,000184836\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00993126 (rel: 2,61e-05) 8,97832e-05\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00993110 (rel: 1,60e-05) 7,63532e-05\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00993106 (rel: 4,59e-06) 8,17323e-05\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00993101 (rel: 4,71e-06) 6,64285e-05\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00993097 (rel: 3,93e-06) 3,14006e-05\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00993097 (rel: 6,18e-07) 2,21036e-05\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00993096 (rel: 6,80e-07) 1,84145e-05\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00993096 (rel: 4,33e-07) 1,44152e-05\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00993095 (rel: 7,79e-07) 6,72372e-06\n",
      "23/03/25 03:26:10 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:10 INFO OWLQN: Val and Grad Norm: 0,00993094 (rel: 2,94e-07) 7,15734e-06\n",
      "23/03/25 03:26:11 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:26:11 INFO OWLQN: Val and Grad Norm: 0,00993094 (rel: 2,81e-08) 3,52142e-06\n",
      "23/03/25 03:26:11 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:11 INFO OWLQN: Val and Grad Norm: 0,00993094 (rel: 8,43e-09) 2,36887e-06\n",
      "23/03/25 03:26:11 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:11 INFO OWLQN: Val and Grad Norm: 0,00993094 (rel: 5,28e-09) 1,63631e-06\n",
      "23/03/25 03:26:11 INFO OWLQN: Converged because max iterations reached\n",
      "23/03/25 03:26:11 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:26:12 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:26:12 INFO OWLQN: Step Size: 31,55\n",
      "23/03/25 03:26:12 INFO OWLQN: Val and Grad Norm: 0,0121457 (rel: 0,0548) 0,00329858\n",
      "23/03/25 03:26:12 INFO OWLQN: Step Size: 0,1250\n",
      "23/03/25 03:26:12 INFO OWLQN: Val and Grad Norm: 0,0120319 (rel: 0,00937) 0,00124397\n",
      "23/03/25 03:26:12 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:12 INFO OWLQN: Val and Grad Norm: 0,0120124 (rel: 0,00162) 0,00153875\n",
      "23/03/25 03:26:12 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:12 INFO OWLQN: Val and Grad Norm: 0,0119646 (rel: 0,00397) 0,000242946\n",
      "23/03/25 03:26:12 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:26:12 INFO OWLQN: Val and Grad Norm: 0,0119635 (rel: 9,24e-05) 0,000517663\n",
      "23/03/25 03:26:13 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:26:13 INFO OWLQN: Val and Grad Norm: 0,0119621 (rel: 0,000124) 0,000221082\n",
      "23/03/25 03:26:13 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:13 INFO OWLQN: Val and Grad Norm: 0,0119608 (rel: 0,000103) 0,000641184\n",
      "23/03/25 03:26:13 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:26:13 INFO OWLQN: Val and Grad Norm: 0,0119581 (rel: 0,000225) 0,000232653\n",
      "23/03/25 03:26:13 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:26:13 INFO OWLQN: Val and Grad Norm: 0,0119573 (rel: 6,71e-05) 0,000256217\n",
      "23/03/25 03:26:13 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:26:13 INFO OWLQN: Val and Grad Norm: 0,0119571 (rel: 1,56e-05) 0,000327052\n",
      "23/03/25 03:26:13 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:26:13 INFO OWLQN: Val and Grad Norm: 0,0119564 (rel: 6,08e-05) 0,000261503\n",
      "23/03/25 03:26:13 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:26:13 INFO OWLQN: Val and Grad Norm: 0,0119560 (rel: 3,58e-05) 0,000184998\n",
      "23/03/25 03:26:13 INFO OWLQN: Step Size: 0,2500\n",
      "23/03/25 03:26:13 INFO OWLQN: Val and Grad Norm: 0,0119558 (rel: 1,86e-05) 0,000165286\n",
      "23/03/25 03:26:13 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:26:13 INFO OWLQN: Val and Grad Norm: 0,0119556 (rel: 1,38e-05) 0,000201470\n",
      "23/03/25 03:26:13 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:13 INFO OWLQN: Val and Grad Norm: 0,0119552 (rel: 3,26e-05) 0,000200429\n",
      "23/03/25 03:26:13 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:13 INFO OWLQN: Val and Grad Norm: 0,0119547 (rel: 4,43e-05) 0,000169831\n",
      "23/03/25 03:26:13 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:13 INFO OWLQN: Val and Grad Norm: 0,0119539 (rel: 6,29e-05) 0,000173204\n",
      "23/03/25 03:26:13 INFO OWLQN: Step Size: 0,5000\n",
      "23/03/25 03:26:13 INFO OWLQN: Val and Grad Norm: 0,0119517 (rel: 0,000187) 0,000328901\n",
      "23/03/25 03:26:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:14 INFO OWLQN: Val and Grad Norm: 0,0119504 (rel: 0,000106) 0,000310604\n",
      "23/03/25 03:26:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:14 INFO OWLQN: Val and Grad Norm: 0,0119501 (rel: 2,40e-05) 0,000253362\n",
      "23/03/25 03:26:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:14 INFO OWLQN: Val and Grad Norm: 0,0119498 (rel: 2,89e-05) 0,000150823\n",
      "23/03/25 03:26:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:14 INFO OWLQN: Val and Grad Norm: 0,0119497 (rel: 1,01e-05) 9,33957e-05\n",
      "23/03/25 03:26:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:14 INFO OWLQN: Val and Grad Norm: 0,0119496 (rel: 4,03e-06) 5,32458e-05\n",
      "23/03/25 03:26:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:14 INFO OWLQN: Val and Grad Norm: 0,0119496 (rel: 1,30e-06) 3,35849e-05\n",
      "23/03/25 03:26:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:14 INFO OWLQN: Val and Grad Norm: 0,0119496 (rel: 5,55e-07) 1,72741e-05\n",
      "23/03/25 03:26:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:14 INFO OWLQN: Val and Grad Norm: 0,0119496 (rel: 1,52e-07) 1,07157e-05\n",
      "23/03/25 03:26:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:14 INFO OWLQN: Val and Grad Norm: 0,0119496 (rel: 7,35e-08) 5,94179e-06\n",
      "23/03/25 03:26:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:14 INFO OWLQN: Val and Grad Norm: 0,0119496 (rel: 2,16e-08) 3,74637e-06\n",
      "23/03/25 03:26:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:14 INFO OWLQN: Val and Grad Norm: 0,0119496 (rel: 1,23e-08) 2,03908e-06\n",
      "23/03/25 03:26:14 INFO OWLQN: Step Size: 1,000\n",
      "23/03/25 03:26:14 INFO OWLQN: Val and Grad Norm: 0,0119496 (rel: 8,80e-09) 1,69552e-06\n",
      "23/03/25 03:26:14 INFO OWLQN: Converged because max iterations reached\n",
      "23/03/25 03:26:15 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:26:15 INFO OWLQN: Converged because gradient converged\n",
      "23/03/25 03:26:16 INFO LBFGS: Step Size: 33,69\n",
      "23/03/25 03:26:16 INFO LBFGS: Val and Grad Norm: 0,0121234 (rel: 0,0441) 0,0146903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/25 03:26:16 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:16 INFO LBFGS: Val and Grad Norm: 0,00809824 (rel: 0,332) 0,00940299\n",
      "23/03/25 03:26:16 INFO StrongWolfeLineSearch: Line search t: 0.503524486923693 fval: 0.006397182048828225 rhs: 0.00809795826762339 cdd: -6.167367411543588E-4\n",
      "23/03/25 03:26:16 INFO LBFGS: Step Size: 0,5035\n",
      "23/03/25 03:26:16 INFO LBFGS: Val and Grad Norm: 0,00639718 (rel: 0,210) 0,00190423\n",
      "23/03/25 03:26:16 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:16 INFO LBFGS: Val and Grad Norm: 0,00630011 (rel: 0,0152) 0,00151576\n",
      "23/03/25 03:26:16 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:16 INFO LBFGS: Val and Grad Norm: 0,00624964 (rel: 0,00801) 0,000824868\n",
      "23/03/25 03:26:16 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:16 INFO LBFGS: Val and Grad Norm: 0,00621970 (rel: 0,00479) 0,000834261\n",
      "23/03/25 03:26:16 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:16 INFO LBFGS: Val and Grad Norm: 0,00610499 (rel: 0,0184) 0,000981719\n",
      "23/03/25 03:26:16 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:16 INFO LBFGS: Val and Grad Norm: 0,00607014 (rel: 0,00571) 0,000901017\n",
      "23/03/25 03:26:16 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:16 INFO LBFGS: Val and Grad Norm: 0,00605237 (rel: 0,00293) 0,000279627\n",
      "23/03/25 03:26:16 INFO LBFGS: Step Size: 1,000\n",
      "23/03/25 03:26:16 INFO LBFGS: Val and Grad Norm: 0,00605087 (rel: 0,000249) 7,01301e-05\n",
      "23/03/25 03:26:16 INFO LBFGS: Converged because max iterations reached\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mcvModel\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mml\u001b[39m.\u001b[32mtuning\u001b[39m.\u001b[32mCrossValidatorModel\u001b[39m = cv_971407aa8bff"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Entraîner le modèle en utilisant la méthode Cross Validation\n",
    "val cvModel = cv.fit(assembledTrainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72b79a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mpredictions\u001b[39m: \u001b[32mDataFrame\u001b[39m = [V1: double, V2: double ... 31 more fields]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Utiliser le modèle pour prédire les classes de l'ensemble de test\n",
    "val predictions = cvModel.transform(assembledTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1cee1ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under ROC: 0.9752201004673393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mareaUnderROC\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.9752201004673393\u001b[39m"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Évaluer les performances du modèle en utilisant l'évaluateur de classification binaire\n",
    "val areaUnderROC = evaluator.evaluate(predictions)\n",
    "println(s\"Area Under ROC: $areaUnderROC\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
